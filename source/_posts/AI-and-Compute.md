---
title: AI and Compute
date: 2019-07-23 14:13:12
categories:
  - Clipping
  - AI
tags:
  - AI
  - Computing resource
  - Blog
  - Statistic
---

# 参考

* [AI and Compute]

[AI and Compute]: https://openai.com/blog/ai-and-compute/
[学習に用いる計算量をペタフロップス/dayで表したグラフ]: https://openai.com/content/images/2018/05/compute_diagram-log@2x-3.png

# メモ

[AI and Compute] は、ムーアの法則を超えるペースで、計算量が増大していることを示すブログ。
以下にポイントを示す。

## 導入

2012年ころからAIの学習に用いられる計算量は3.5か月あたり2倍に増えてきた。
（ムーアの法則では18か月あたりに2倍）

[学習に用いる計算量をペタフロップス/dayで表したグラフ] に計算量増加のグラフが載っている。
AlexNetから始まり、AlphaGo Zeroまで。
30万倍になった。

## 概要

AIを進化させた3要素。

* アルゴリズムの進化
* データの改善
* 計算可能量の増大

ここでは計算可能量の増大に着目。
特にひとつのモデルを学習するのに用いられる計算量に着目。
概ね10倍/年ペース。
これにはそれ用のカスタムハードウェア（GPU、TPUなど）の導入に加え、
計算リソースを並列処理で使い切る手法の改善も寄与している。


## 時代

* 2012年より前
  * 機械学習向けにGPUを使っていなかった
* 2012年〜2014年
  * 1〜8個程度のGPUを使用
  * 1〜2TFLOPS
* 2014〜2016年
  * 10〜100GPUを使用
  * 5〜10TFLOPS
* 2016〜2017年
  * TPUなどが登場
  * アルゴリズム上も並列度がとても高まった。

## 将来展望

多くのベンチャーがHWを開発。例えばFLOPSあたりの単価を下げる効果が期待される。
アルゴリズム側も進化を続けている。

一方で費用と物理制約の影響は大きい。
例えば、最も大きなモデルを学習するのに必要な計算リソースは100万ドル＝1億円である。
一方で、現在の多くの企業が支払っているのは、学習よりも推論側である。したがって、バランスを考えると
学習にもっと支払えるはず。
世の中のHW購入のバジェットは1兆ドルといわれており、その数字に照らし合わせるとまだまだ拡大の余地が残っている。

## 付録

計算方法についての補足が載っている。
FLOPSを直接計算可能な場合にはそうしたし、そうでない場合は使用したGPU数などから算出した、とのこと。
多くのケースで著者にも確認したそうだ。
