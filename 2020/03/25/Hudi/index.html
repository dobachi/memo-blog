<!DOCTYPE html>
<html lang=ja>
<head>
    <meta charset="utf-8">
    
    <title>Hudi | memo-blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="参考 メモ  公式ドキュメント クイックスタートから確認（version 0.5.2前提）  org.apache.hudi.DefaultSource#createRelation（書き込み） org.apache.hudi.DefaultSource#createRelation（読み込み） IncrementalRelation   Hudiへの書き込み  オペレーション種類 Delt">
<meta name="keywords" content="Storage Layer,Apache Hudi">
<meta property="og:type" content="article">
<meta property="og:title" content="Hudi">
<meta property="og:url" content="https://dobachi.github.io/memo-blog/2020/03/25/Hudi/index.html">
<meta property="og:site_name" content="memo-blog">
<meta property="og:description" content="参考 メモ  公式ドキュメント クイックスタートから確認（version 0.5.2前提）  org.apache.hudi.DefaultSource#createRelation（書き込み） org.apache.hudi.DefaultSource#createRelation（読み込み） IncrementalRelation   Hudiへの書き込み  オペレーション種類 Delt">
<meta property="og:locale" content="ja">
<meta property="og:updated_time" content="2023-08-01T04:17:48.052Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hudi">
<meta name="twitter:description" content="参考 メモ  公式ドキュメント クイックスタートから確認（version 0.5.2前提）  org.apache.hudi.DefaultSource#createRelation（書き込み） org.apache.hudi.DefaultSource#createRelation（読み込み） IncrementalRelation   Hudiへの書き込み  オペレーション種類 Delt">
    

    
        <link rel="alternate" href="/" title="memo-blog" type="application/atom+xml" />
    

    

    <link rel="stylesheet" href="/memo-blog/libs/font-awesome5/css/fontawesome.min.css">
    <link rel="stylesheet" href="/memo-blog/libs/font-awesome5/css/fa-brands.min.css">
    <link rel="stylesheet" href="/memo-blog/libs/font-awesome5/css/fa-solid.min.css">
    <link rel="stylesheet" href="/memo-blog/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/memo-blog/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/memo-blog/css/style.css">

    <script src="/memo-blog/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/memo-blog/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/memo-blog/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-155235180-1', 'auto');
ga('send', 'pageview');

</script>
    
    
    


</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/memo-blog/" id="logo">
                <i class="logo"></i>
                <span class="site-title">memo-blog</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/memo-blog/.">Home</a>
                
                    <a class="main-nav-link" href="/memo-blog/archives">Archives</a>
                
                    <a class="main-nav-link" href="/memo-blog/categories">Categories</a>
                
                    <a class="main-nav-link" href="/memo-blog/tags">Tags</a>
                
                    <a class="main-nav-link" href="/memo-blog/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/memo-blog/css/images/avatar.png" />
                            <i class="fas fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="検索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fas fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '投稿',
            PAGES: 'Pages',
            CATEGORIES: 'カテゴリ',
            TAGS: 'タグ',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/memo-blog/',
        CONTENT_URL: '/memo-blog/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/memo-blog/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/memo-blog/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/memo-blog/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/memo-blog/categories">Categories</a></td>
                
                    <td><a class="main-nav-link" href="/memo-blog/tags">Tags</a></td>
                
                    <td><a class="main-nav-link" href="/memo-blog/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="検索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/memo-blog/css/images/avatar.png" />
            <h2 id="name">dobachi</h2>
            <h3 id="title">man of leisure</h3>
            <span id="location"><i class="fas fa-map-marker-alt" style="padding-right: 5px"></i>Tokyo, Japan</span>
            <a id="follow" target="_blank" href="https://github.com/dobachi">フォローする</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                204
                <span>投稿</span>
            </div>
            <div class="article-info-block">
                225
                <span>タグ</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="http://github.com/dobachi" target="_blank" title="github" class=tooltip>
                            <i class="fab fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/memo-blog/" target="_blank" title="rss" class=tooltip>
                            <i class="fab fa-rss"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-Hudi" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            Hudi
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/memo-blog/2020/03/25/Hudi/">
            <time datetime="2020-03-25T14:40:12.000Z" itemprop="datePublished">2020-03-25</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/">Knowledge Management</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/Storage-Layer/">Storage Layer</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/Storage-Layer/Hudi/">Hudi</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/memo-blog/tags/Apache-Hudi/">Apache Hudi</a>, <a class="tag-link" href="/memo-blog/tags/Storage-Layer/">Storage Layer</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <div id="TOC">
	<ul>
<li><a href="#参考" id="toc-参考">参考</a></li>
<li><a href="#メモ" id="toc-メモ">メモ</a>
<ul>
<li><a href="#公式ドキュメント" id="toc-公式ドキュメント">公式ドキュメント</a></li>
<li><a href="#クイックスタートから確認version-0.5.2前提" id="toc-クイックスタートから確認version-0.5.2前提">クイックスタートから確認（version
0.5.2前提）</a>
<ul>
<li><a href="#org.apache.hudi.defaultsourcecreaterelation書き込み" id="toc-org.apache.hudi.defaultsourcecreaterelation書き込み">org.apache.hudi.DefaultSource#createRelation（書き込み）</a></li>
<li><a href="#org.apache.hudi.defaultsourcecreaterelation読み込み" id="toc-org.apache.hudi.defaultsourcecreaterelation読み込み">org.apache.hudi.DefaultSource#createRelation（読み込み）</a></li>
<li><a href="#incrementalrelation" id="toc-incrementalrelation">IncrementalRelation</a></li>
</ul></li>
</ul></li>
<li><a href="#hudiへの書き込み" id="toc-hudiへの書き込み">Hudiへの書き込み</a>
<ul>
<li><a href="#オペレーション種類" id="toc-オペレーション種類">オペレーション種類</a></li>
<li><a href="#deltastreamer" id="toc-deltastreamer">DeltaStreamer</a>
<ul>
<li><a href="#動作確認" id="toc-動作確認">動作確認</a></li>
<li><a href="#実装確認" id="toc-実装確認">実装確認</a></li>
</ul></li>
</ul></li>
</ul>
</div>
<h1><span id="参考">参考</span></h1>
<ul>
<li><p><a href="https://hudi.apache.org/" target="_blank" rel="noopener">公式ドキュメント</a></p></li>
<li><p><a href="https://hudi.apache.org/docs/quick-start-guide.html" target="_blank" rel="noopener">Quick Start
Guide</a></p></li>
<li><p><a href="https://hudi.apache.org/docs/writing_data.html" target="_blank" rel="noopener">Writing
Hudi Tables</a></p></li>
<li><p><a href="https://hudi.apache.org/docs/writing_data.html#deltastreamer" target="_blank" rel="noopener">公式ドキュメントのData
Streamer</a></p></li>
<li><p><a href="https://github.com/apurvam/streams-prototyping" target="_blank" rel="noopener">apurvam
streams-prototyping</a></p></li>
</ul>
<h1><span id="メモ">メモ</span></h1>
<h2><span id="公式ドキュメント">公式ドキュメント</span></h2>
<p>載っている特徴は、以下の通り。</p>
<ul>
<li>Upsert support with fast, pluggable indexing.</li>
<li>Atomically publish data with rollback support.</li>
<li>Snapshot isolation between writer &amp; queries.</li>
<li>Savepoints for data recovery.</li>
<li>Manages file sizes, layout using statistics.</li>
<li>Async compaction of row &amp; columnar data.</li>
<li>Timeline metadata to track lineage.</li>
</ul>
<h2><span id="クイックスタートから確認version052前提">クイックスタートから確認（version
0.5.2前提）</span></h2>
<p><a href="https://hudi.apache.org/docs/quick-start-guide.html" target="_blank" rel="noopener">Quick
Start Guide</a> を参考に進める。</p>
<p>公式ドキュメントではSpark2.4.4を利用しているが、ここでは2.4.5を利用する。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> SPARK_HOME=/opt/spark/default</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-shell \</span></span><br><span class="line">  --packages org.apache.hudi:hudi-spark-bundle_2.11:0.5.2-incubating,org.apache.spark:spark-avro_2.11:2.4.5 \</span><br><span class="line">  --conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer'</span><br></pre></td></tr></table></figure>
<p>必要なライブラリをインポート</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">import</span> org.apache.hudi.<span class="type">QuickstartUtils</span>._</span><br><span class="line">scala&gt; <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.<span class="type">SaveMode</span>._</span><br><span class="line">scala&gt; <span class="keyword">import</span> org.apache.hudi.<span class="type">DataSourceReadOptions</span>._</span><br><span class="line">scala&gt; <span class="keyword">import</span> org.apache.hudi.<span class="type">DataSourceWriteOptions</span>._</span><br><span class="line">scala&gt; <span class="keyword">import</span> org.apache.hudi.config.<span class="type">HoodieWriteConfig</span>._</span><br><span class="line">scala&gt; </span><br><span class="line">scala&gt; <span class="keyword">val</span> tableName = <span class="string">"hudi_trips_cow"</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> basePath = <span class="string">"file:///tmp/hudi_trips_cow"</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> dataGen = <span class="keyword">new</span> <span class="type">DataGenerator</span></span><br></pre></td></tr></table></figure>
<p>ダミーデータには
<code>org.apache.hudi.QuickstartUtils.DataGenerator</code>
クラスを利用する。 以下の例では、
<code>org.apache.hudi.QuickstartUtils.DataGenerator#generateInserts</code>
メソッドを利用しデータを生成するが、 どういうレコードが生成されるかは、
<code>org.apache.hudi.QuickstartUtils.DataGenerator#generateRandomValue</code>
メソッドあたりを見るとわかる。</p>
<p>ダミーデータを生成し、Spark DataFrameに変換。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> inserts = convertToStringList(dataGen.generateInserts(<span class="number">10</span>))</span><br><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(spark.sparkContext.parallelize(inserts, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>中身は以下。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.show</span><br><span class="line">+-------------------+-------------------+----------+-------------------+-------------------+------------------+--------------------+---------+---+--------------------+</span><br><span class="line">|          begin_lat|          begin_lon|    driver|            end_lat|            end_lon|              fare|       partitionpath|    rider| ts|                uuid|</span><br><span class="line">+-------------------+-------------------+----------+-------------------+-------------------+------------------+--------------------+---------+---+--------------------+</span><br><span class="line">| <span class="number">0.4726905879569653</span>|<span class="number">0.46157858450465483</span>|driver<span class="number">-213</span>|  <span class="number">0.754803407008858</span>| <span class="number">0.9671159942018241</span>|<span class="number">34.158284716382845</span>|americas/brazil/s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">28432</span>dec<span class="number">-53</span>eb<span class="number">-402.</span>..|</span><br><span class="line">| <span class="number">0.6100070562136587</span>| <span class="number">0.8779402295427752</span>|driver<span class="number">-213</span>| <span class="number">0.3407870505929602</span>| <span class="number">0.5030798142293655</span>|  <span class="number">43.4923811219014</span>|americas/brazil/s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">1</span>bd3905e-a6c4<span class="number">-404.</span>..|</span><br><span class="line">| <span class="number">0.5731835407930634</span>| <span class="number">0.4923479652912024</span>|driver<span class="number">-213</span>|<span class="number">0.08988581780930216</span>|<span class="number">0.42520899698713666</span>| <span class="number">64.27696295884016</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|c9cc8f4b-acee<span class="number">-413.</span>..|</span><br><span class="line">|<span class="number">0.21624150367601136</span>|<span class="number">0.14285051259466197</span>|driver<span class="number">-213</span>| <span class="number">0.5890949624813784</span>| <span class="number">0.0966823831927115</span>| <span class="number">93.56018115236618</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">4</span>be1c199<span class="number">-86</span>dc<span class="number">-489.</span>..|</span><br><span class="line">|   <span class="number">0.40613510977307</span>| <span class="number">0.5644092139040959</span>|driver<span class="number">-213</span>|  <span class="number">0.798706304941517</span>|<span class="number">0.02698359227182834</span>|<span class="number">17.851135255091155</span>|  asia/india/chennai|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">83</span>f4d3df<span class="number">-46</span>c1<span class="number">-48</span>a...|</span><br><span class="line">| <span class="number">0.8742041526408587</span>| <span class="number">0.7528268153249502</span>|driver<span class="number">-213</span>| <span class="number">0.9197827128888302</span>|  <span class="number">0.362464770874404</span>|<span class="number">19.179139106643607</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|cb8b392d-c9d0<span class="number">-445.</span>..|</span><br><span class="line">| <span class="number">0.1856488085068272</span>| <span class="number">0.9694586417848392</span>|driver<span class="number">-213</span>|<span class="number">0.38186367037201974</span>|<span class="number">0.25252652214479043</span>| <span class="number">33.92216483948643</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">66</span>aaf87d<span class="number">-4786</span><span class="number">-4</span>d0...|</span><br><span class="line">| <span class="number">0.0750588760043035</span>|<span class="number">0.03844104444445928</span>|driver<span class="number">-213</span>|<span class="number">0.04376353354538354</span>| <span class="number">0.6346040067610669</span>| <span class="number">66.62084366450246</span>|americas/brazil/s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|c5a335f5-c57f<span class="number">-4</span>f5...|</span><br><span class="line">|  <span class="number">0.651058505660742</span>| <span class="number">0.8192868687714224</span>|driver<span class="number">-213</span>|<span class="number">0.20714896002914462</span>|<span class="number">0.06224031095826987</span>| <span class="number">41.06290929046368</span>|  asia/india/chennai|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">53026</span>eda<span class="number">-28</span>c4<span class="number">-4</span>d8...|</span><br><span class="line">|<span class="number">0.11488393157088261</span>| <span class="number">0.6273212202489661</span>|driver<span class="number">-213</span>| <span class="number">0.7454678537511295</span>| <span class="number">0.3954939864908973</span>| <span class="number">27.79478688582596</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|cd42df54<span class="number">-5215</span><span class="number">-402.</span>..|</span><br><span class="line">+-------------------+-------------------+----------+-------------------+-------------------+------------------+--------------------+---------+---+--------------------+</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.write.format(<span class="string">"hudi"</span>).</span><br><span class="line">         options(getQuickstartWriteConfigs).</span><br><span class="line">         option(<span class="type">PRECOMBINE_FIELD_OPT_KEY</span>, <span class="string">"ts"</span>).</span><br><span class="line">         option(<span class="type">RECORDKEY_FIELD_OPT_KEY</span>, <span class="string">"uuid"</span>).</span><br><span class="line">         option(<span class="type">PARTITIONPATH_FIELD_OPT_KEY</span>, <span class="string">"partitionpath"</span>).</span><br><span class="line">         option(<span class="type">TABLE_NAME</span>, tableName).</span><br><span class="line">         mode(<span class="type">Overwrite</span>).</span><br><span class="line">         save(basePath)</span><br></pre></td></tr></table></figure>
<p>なお、生成されたファイルは以下の通り。
<code>PARTITIONPATH_FIELD_OPT_KEY</code>
で指定したカラムをパーティションキーとして用いていることがわかる。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls -R /tmp/hudi_trips_cow/</span></span><br><span class="line">/tmp/hudi_trips_cow/:</span><br><span class="line">americas  asia</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/americas:</span><br><span class="line">brazil  united_states</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/americas/brazil:</span><br><span class="line">sao_paulo</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/americas/brazil/sao_paulo:</span><br><span class="line">ae28c85a-38f0-487f-a42d-3a0babc9d321-0_0-21-25_20200329002247.parquet</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/americas/united_states:</span><br><span class="line">san_francisco</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/americas/united_states/san_francisco:</span><br><span class="line">849db286-1cbe-4a1f-b544-9939893e99f8-0_1-21-26_20200329002247.parquet</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/asia:</span><br><span class="line">india</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/asia/india:</span><br><span class="line">chennai</span><br><span class="line"></span><br><span class="line">/tmp/hudi_trips_cow/asia/india/chennai:</span><br><span class="line">2ebfbab0-4f8f-42db-b79e-1c0cbcc3cf39-0_2-21-27_20200329002247.parquet</span><br></pre></td></tr></table></figure>
<p>保存したデータを読み出してみる。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> tripsSnapshotDF = spark.</span><br><span class="line">         read.</span><br><span class="line">         format(<span class="string">"hudi"</span>).</span><br><span class="line">         load(basePath + <span class="string">"/*/*/*/*"</span>)</span><br><span class="line">scala&gt; tripsSnapshotDF.createOrReplaceTempView(<span class="string">"hudi_trips_snapshot"</span>)</span><br></pre></td></tr></table></figure>
<p>中身は以下の通り。
元データに対し、Hudiのカラムが追加されていることがわかる。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; tripsSnapshotDF.show</span><br><span class="line">+-------------------+--------------------+--------------------+----------------------+--------------------+-------------------+-------------------+----------+-------------------+-------------------+------------------+--------------------+---------+---+--------------------+</span><br><span class="line">|_hoodie_commit_time|_hoodie_commit_seqno|  _hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|          begin_lat|          begin_lon|    driver|            end_lat|            end_lon|              fare|       partitionpath|    rider| ts|                uuid|</span><br><span class="line">+-------------------+--------------------+--------------------+----------------------+--------------------+-------------------+-------------------+----------+-------------------+-------------------+------------------+--------------------+---------+---+--------------------+</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_1_1|<span class="number">7695</span>c291<span class="number">-8530</span><span class="number">-473.</span>..|  americas/united_s...|<span class="number">849</span>db286<span class="number">-1</span>cbe<span class="number">-4</span>a1...|<span class="number">0.21624150367601136</span>|<span class="number">0.14285051259466197</span>|driver<span class="number">-213</span>| <span class="number">0.5890949624813784</span>| <span class="number">0.0966823831927115</span>| <span class="number">93.56018115236618</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">7695</span>c291<span class="number">-8530</span><span class="number">-473.</span>..|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_1_3|<span class="number">2</span>f06fcd2<span class="number">-8296</span><span class="number">-423.</span>..|  americas/united_s...|<span class="number">849</span>db286<span class="number">-1</span>cbe<span class="number">-4</span>a1...| <span class="number">0.5731835407930634</span>| <span class="number">0.4923479652912024</span>|driver<span class="number">-213</span>|<span class="number">0.08988581780930216</span>|<span class="number">0.42520899698713666</span>| <span class="number">64.27696295884016</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">2</span>f06fcd2<span class="number">-8296</span><span class="number">-423.</span>..|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_1_5|<span class="number">6</span>ebc4028<span class="number">-9</span>aae<span class="number">-420.</span>..|  americas/united_s...|<span class="number">849</span>db286<span class="number">-1</span>cbe<span class="number">-4</span>a1...| <span class="number">0.8742041526408587</span>| <span class="number">0.7528268153249502</span>|driver<span class="number">-213</span>| <span class="number">0.9197827128888302</span>|  <span class="number">0.362464770874404</span>|<span class="number">19.179139106643607</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">6</span>ebc4028<span class="number">-9</span>aae<span class="number">-420.</span>..|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_1_6|<span class="number">8</span>bf60390-ad41<span class="number">-4</span>b0...|  americas/united_s...|<span class="number">849</span>db286<span class="number">-1</span>cbe<span class="number">-4</span>a1...|<span class="number">0.11488393157088261</span>| <span class="number">0.6273212202489661</span>|driver<span class="number">-213</span>| <span class="number">0.7454678537511295</span>| <span class="number">0.3954939864908973</span>| <span class="number">27.79478688582596</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">8</span>bf60390-ad41<span class="number">-4</span>b0...|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_1_7|<span class="number">762e8</span>cb2<span class="number">-8806</span><span class="number">-47</span>d...|  americas/united_s...|<span class="number">849</span>db286<span class="number">-1</span>cbe<span class="number">-4</span>a1...| <span class="number">0.1856488085068272</span>| <span class="number">0.9694586417848392</span>|driver<span class="number">-213</span>|<span class="number">0.38186367037201974</span>|<span class="number">0.25252652214479043</span>| <span class="number">33.92216483948643</span>|americas/united_s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">762e8</span>cb2<span class="number">-8806</span><span class="number">-47</span>d...|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_0_8|<span class="number">28622337</span>-d76b<span class="number">-442.</span>..|  americas/brazil/s...|ae28c85a<span class="number">-38</span>f0<span class="number">-487.</span>..| <span class="number">0.6100070562136587</span>| <span class="number">0.8779402295427752</span>|driver<span class="number">-213</span>| <span class="number">0.3407870505929602</span>| <span class="number">0.5030798142293655</span>|  <span class="number">43.4923811219014</span>|americas/brazil/s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">28622337</span>-d76b<span class="number">-442.</span>..|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_0_9|<span class="number">33</span>aec15d<span class="number">-356</span>f<span class="number">-475.</span>..|  americas/brazil/s...|ae28c85a<span class="number">-38</span>f0<span class="number">-487.</span>..| <span class="number">0.0750588760043035</span>|<span class="number">0.03844104444445928</span>|driver<span class="number">-213</span>|<span class="number">0.04376353354538354</span>| <span class="number">0.6346040067610669</span>| <span class="number">66.62084366450246</span>|americas/brazil/s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">33</span>aec15d<span class="number">-356</span>f<span class="number">-475.</span>..|</span><br><span class="line">|     <span class="number">20200329002247</span>| <span class="number">20200329002247</span>_0_10|<span class="number">2</span>d71c9a3<span class="number">-26</span>a3<span class="number">-40</span>b...|  americas/brazil/s...|ae28c85a<span class="number">-38</span>f0<span class="number">-487.</span>..| <span class="number">0.4726905879569653</span>|<span class="number">0.46157858450465483</span>|driver<span class="number">-213</span>|  <span class="number">0.754803407008858</span>| <span class="number">0.9671159942018241</span>|<span class="number">34.158284716382845</span>|americas/brazil/s...|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">2</span>d71c9a3<span class="number">-26</span>a3<span class="number">-40</span>b...|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_2_2|a997a8f0<span class="number">-4</span>ab6<span class="number">-4</span>d5...|    asia/india/chennai|<span class="number">2</span>ebfbab0<span class="number">-4</span>f8f<span class="number">-42</span>d...|   <span class="number">0.40613510977307</span>| <span class="number">0.5644092139040959</span>|driver<span class="number">-213</span>|  <span class="number">0.798706304941517</span>|<span class="number">0.02698359227182834</span>|<span class="number">17.851135255091155</span>|  asia/india/chennai|rider<span class="number">-213</span>|<span class="number">0.0</span>|a997a8f0<span class="number">-4</span>ab6<span class="number">-4</span>d5...|</span><br><span class="line">|     <span class="number">20200329002247</span>|  <span class="number">20200329002247</span>_2_4|<span class="number">271</span>de424-a0f8<span class="number">-427.</span>..|    asia/india/chennai|<span class="number">2</span>ebfbab0<span class="number">-4</span>f8f<span class="number">-42</span>d...|  <span class="number">0.651058505660742</span>| <span class="number">0.8192868687714224</span>|driver<span class="number">-213</span>|<span class="number">0.20714896002914462</span>|<span class="number">0.06224031095826987</span>| <span class="number">41.06290929046368</span>|  asia/india/chennai|rider<span class="number">-213</span>|<span class="number">0.0</span>|<span class="number">271</span>de424-a0f8<span class="number">-427.</span>..|</span><br><span class="line">+-------------------+--------------------+--------------------+----------------------+--------------------+-------------------+-------------------+----------+-------------------+-------------------+------------------+--------------------+---------+---+--------------------+</span><br></pre></td></tr></table></figure>
<p>上記の通り、SparkのData Source機能を利用している。
中では、<code>org.apache.hudi.DefaultSource#createRelation</code>
メソッドが用いられる。</p>
<p>つづいて、更新を試す。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> updates = convertToStringList(dataGen.generateUpdates(<span class="number">10</span>))</span><br><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(spark.sparkContext.parallelize(updates, <span class="number">2</span>))</span><br><span class="line">scala&gt; df.write.format(<span class="string">"hudi"</span>).</span><br><span class="line">         options(getQuickstartWriteConfigs).</span><br><span class="line">         option(<span class="type">PRECOMBINE_FIELD_OPT_KEY</span>, <span class="string">"ts"</span>).</span><br><span class="line">         option(<span class="type">RECORDKEY_FIELD_OPT_KEY</span>, <span class="string">"uuid"</span>).</span><br><span class="line">         option(<span class="type">PARTITIONPATH_FIELD_OPT_KEY</span>, <span class="string">"partitionpath"</span>).</span><br><span class="line">         option(<span class="type">TABLE_NAME</span>, tableName).</span><br><span class="line">         mode(<span class="type">Append</span>).</span><br><span class="line">         save(basePath)</span><br></pre></td></tr></table></figure>
<p>もう一度、DataFrameとして読み出すと、レコードが追加されていることを確かめられる。（ここでは省略）
この後の、 <code>incremental</code>
クエリタイプの実験のため、上記の更新を幾度か実行しておく。</p>
<p>つづいて、 <code>incremental</code> クエリタイプで読み出す。</p>
<p>一度読み出し、最初のコミット時刻を取り出す。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.</span><br><span class="line">         read.</span><br><span class="line">         format(<span class="string">"hudi"</span>).</span><br><span class="line">         load(basePath + <span class="string">"/*/*/*/*"</span>).</span><br><span class="line">         createOrReplaceTempView(<span class="string">"hudi_trips_snapshot"</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> commits = spark.sql(<span class="string">"select distinct(_hoodie_commit_time) as commitTime from  hudi_trips_snapshot order by commitTime"</span>).map(k =&gt; k.getString(<span class="number">0</span>)).take(<span class="number">50</span>)</span><br><span class="line">scala&gt; <span class="keyword">val</span> beginTime = commits(commits.length - <span class="number">2</span>) <span class="comment">// commit time we are interested in</span></span><br></pre></td></tr></table></figure>
<p>今回は、初回書き込みに加えて2回更新したので、 <code>commits</code>
は以下の通り。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; commits</span><br><span class="line">res12: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="number">20200330002239</span>, <span class="number">20200330002354</span>, <span class="number">20200330003142</span>)</span><br></pre></td></tr></table></figure>
<p>また、今回「読み込みの最初」とするコミットは、以下の通り。
つまり、2回目の更新時。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; beginTime</span><br><span class="line">res13: <span class="type">String</span> = <span class="number">20200330002354</span></span><br></pre></td></tr></table></figure>
<p>では、 <code>incremental</code> クエリタイプで読み出す。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> tripsIncrementalDF = spark.read.format(<span class="string">"hudi"</span>).</span><br><span class="line">         option(<span class="type">QUERY_TYPE_OPT_KEY</span>, <span class="type">QUERY_TYPE_INCREMENTAL_OPT_VAL</span>).</span><br><span class="line">         option(<span class="type">BEGIN_INSTANTTIME_OPT_KEY</span>, beginTime).</span><br><span class="line">         load(basePath)</span><br><span class="line">scala&gt; tripsIncrementalDF.createOrReplaceTempView(<span class="string">"hudi_trips_incremental"</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">"select `_hoodie_commit_time`, fare, begin_lon, begin_lat, ts from  hudi_trips_incremental where fare &gt; 20.0"</span>).show()</span><br></pre></td></tr></table></figure>
<p>結果は以下のようなイメージ。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">"select `_hoodie_commit_time`, fare, begin_lon, begin_lat, ts from  hudi_trips_incremental where fare &gt; 20.0"</span>).show()</span><br><span class="line">+-------------------+------------------+--------------------+-------------------+---+</span><br><span class="line">|_hoodie_commit_time|              fare|           begin_lon|          begin_lat| ts|</span><br><span class="line">+-------------------+------------------+--------------------+-------------------+---+</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">87.68271062363665</span>|  <span class="number">0.9273857651526887</span>| <span class="number">0.1620033132033215</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">40.44073446276323</span>|<span class="number">9.842943407509797E-4</span>|<span class="number">0.47631824594751015</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">45.39370966816483</span>|    <span class="number">0.65888271115305</span>| <span class="number">0.8535610661589833</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>|<span class="number">47.332186591003044</span>|  <span class="number">0.8006023508896579</span>| <span class="number">0.9025851737325563</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">93.34457064050349</span>|  <span class="number">0.6331319396951335</span>| <span class="number">0.5375953886834237</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>|<span class="number">31.065524210209226</span>|  <span class="number">0.7608842984578864</span>| <span class="number">0.9514417909802292</span>|<span class="number">0.0</span>|</span><br><span class="line">+-------------------+------------------+--------------------+-------------------+---+</span><br></pre></td></tr></table></figure>
<p>なお、ここでbeginTimeを1遡ることにすると…。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> beginTime = commits(commits.length - <span class="number">3</span>) <span class="comment">// commit time we are interested in</span></span><br></pre></td></tr></table></figure>
<p>以下のように、2回目のコミットも含まれるようになる。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">"select `_hoodie_commit_time`, fare, begin_lon, begin_lat, ts from  hudi_trips_incremental where fare &gt; 20.0"</span>).show()</span><br><span class="line">+-------------------+------------------+--------------------+-------------------+---+</span><br><span class="line">|_hoodie_commit_time|              fare|           begin_lon|          begin_lat| ts|</span><br><span class="line">+-------------------+------------------+--------------------+-------------------+---+</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">87.68271062363665</span>|  <span class="number">0.9273857651526887</span>| <span class="number">0.1620033132033215</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">40.44073446276323</span>|<span class="number">9.842943407509797E-4</span>|<span class="number">0.47631824594751015</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">45.39370966816483</span>|    <span class="number">0.65888271115305</span>| <span class="number">0.8535610661589833</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>|<span class="number">47.332186591003044</span>|  <span class="number">0.8006023508896579</span>| <span class="number">0.9025851737325563</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330002354</span>| <span class="number">39.09858962414072</span>| <span class="number">0.08151154133724581</span>|<span class="number">0.21729959707372848</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>| <span class="number">93.34457064050349</span>|  <span class="number">0.6331319396951335</span>| <span class="number">0.5375953886834237</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330002354</span>| <span class="number">80.87869643345753</span>|  <span class="number">0.0748253615757305</span>| <span class="number">0.9787639413761751</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330003142</span>|<span class="number">31.065524210209226</span>|  <span class="number">0.7608842984578864</span>| <span class="number">0.9514417909802292</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330002354</span>|<span class="number">21.602186045036387</span>|   <span class="number">0.772134626462835</span>| <span class="number">0.3291184473506418</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330002354</span>| <span class="number">43.41497201940956</span>|  <span class="number">0.6226833057042072</span>| <span class="number">0.5501675314928346</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330002354</span>| <span class="number">35.71294622426758</span>|  <span class="number">0.6696123015022845</span>| <span class="number">0.7318572150654761</span>|<span class="number">0.0</span>|</span><br><span class="line">|     <span class="number">20200330002354</span>| <span class="number">67.30906296028802</span>| <span class="number">0.16768228612130764</span>|<span class="number">0.29666655980198253</span>|<span class="number">0.0</span>|</span><br><span class="line">+-------------------+------------------+--------------------+-------------------+---+</span><br></pre></td></tr></table></figure>
<h3><span id="orgapachehudidefaultsourcecreaterelation書き込み">org.apache.hudi.DefaultSource#createRelation（書き込み）</span></h3>
<p>クイックスタートで、例えば更新などする際の動作を確認する。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.write.format(<span class="string">"hudi"</span>).</span><br><span class="line">     |   options(getQuickstartWriteConfigs).</span><br><span class="line">     |   option(<span class="type">PRECOMBINE_FIELD_OPT_KEY</span>, <span class="string">"ts"</span>).</span><br><span class="line">     |   option(<span class="type">RECORDKEY_FIELD_OPT_KEY</span>, <span class="string">"uuid"</span>).</span><br><span class="line">     |   option(<span class="type">PARTITIONPATH_FIELD_OPT_KEY</span>, <span class="string">"partitionpath"</span>).</span><br><span class="line">     |   option(<span class="type">TABLE_NAME</span>, tableName).</span><br><span class="line">     |   mode(<span class="type">Append</span>).</span><br><span class="line">     |   save(basePath)</span><br></pre></td></tr></table></figure>
<p>のような例を実行する際、内部的には
<code>org.apache.hudi.DefaultSource#createRelation</code>
が呼ばれる。</p>
<p>org/apache/hudi/DefaultSource.scala:85</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createRelation</span></span>(sqlContext: <span class="type">SQLContext</span>,</span><br><span class="line">                            mode: <span class="type">SaveMode</span>,</span><br><span class="line">                            optParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</span><br><span class="line">                            df: <span class="type">DataFrame</span>): <span class="type">BaseRelation</span> = &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> parameters = <span class="type">HoodieSparkSqlWriter</span>.parametersWithWriteDefaults(optParams)</span><br><span class="line">  <span class="type">HoodieSparkSqlWriter</span>.write(sqlContext, mode, parameters, df)</span><br><span class="line">  createRelation(sqlContext, parameters, df.schema)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上記メソッド内では、
<code>org.apache.hudi.HoodieSparkSqlWriter$#write</code>
メソッドが呼ばれており、 これが書き込みの実態である。 なお、その下の
<code>org.apache.hudi.DefaultSource#createRelation</code>
は、読み込み時に呼ばれるものと同一。</p>
<p>ここでは <code>org.apache.hudi.HoodieSparkSqlWriter#write</code>
メソッドを確認する。
当該メソッドの冒頭では、オペレーションの判定などいくつか前処理が行われた後、
以下の箇所から実際に書き出す処理が定義されている。</p>
<p>org/apache/hudi/HoodieSparkSqlWriter.scala:85</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> (writeStatuses, writeClient: <span class="type">HoodieWriteClient</span>[<span class="type">HoodieRecordPayload</span>[<span class="type">Nothing</span>]]) =</span><br><span class="line">  <span class="keyword">if</span> (!operation.equalsIgnoreCase(<span class="type">DELETE_OPERATION_OPT_VAL</span>)) &#123;</span><br><span class="line">  <span class="comment">// register classes &amp; schemas</span></span><br><span class="line">  <span class="keyword">val</span> structName = <span class="string">s"<span class="subst">$&#123;tblName.get&#125;</span>_record"</span></span><br><span class="line">  <span class="keyword">val</span> nameSpace = <span class="string">s"hoodie.<span class="subst">$&#123;tblName.get&#125;</span>"</span></span><br><span class="line">  sparkContext.getConf.registerKryoClasses(</span><br><span class="line">    <span class="type">Array</span>(classOf[org.apache.avro.generic.<span class="type">GenericData</span>],</span><br><span class="line">      classOf[org.apache.avro.<span class="type">Schema</span>]))</span><br><span class="line">  <span class="keyword">val</span> schema = <span class="type">AvroConversionUtils</span>.convertStructTypeToAvroSchema(df.schema, structName, nameSpace)</span><br><span class="line">  sparkContext.getConf.registerAvroSchemas(schema)</span><br><span class="line"></span><br><span class="line">  (snip)</span><br></pre></td></tr></table></figure>
<p>まず <code>delete</code>
オペレーションかどうかで処理が別れるが、上記の例では <code>upsert</code>
オペレーションなので一旦そのまま読み進める。
ネームスペース（データベースやテーブル？）を取得した後、SparkのStructTypeで保持されたスキーマ情報を、AvroのSchemaに変換する。
変換されたスキーマをSparkで登録する。</p>
<p>つづいて、DataFrameをRDDに変換する。</p>
<p>org/apache/hudi/HoodieSparkSqlWriter.scala:97</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Convert to RDD[HoodieRecord]</span></span><br><span class="line"><span class="keyword">val</span> keyGenerator = <span class="type">DataSourceUtils</span>.createKeyGenerator(toProperties(parameters))</span><br><span class="line"><span class="keyword">val</span> genericRecords: <span class="type">RDD</span>[<span class="type">GenericRecord</span>] = <span class="type">AvroConversionUtils</span>.createRdd(df, structName, nameSpace)</span><br><span class="line"><span class="keyword">val</span> hoodieAllIncomingRecords = genericRecords.map(gr =&gt; &#123;</span><br><span class="line">  <span class="keyword">val</span> orderingVal = <span class="type">DataSourceUtils</span>.getNestedFieldValAsString(</span><br><span class="line">    gr, parameters(<span class="type">PRECOMBINE_FIELD_OPT_KEY</span>), <span class="literal">false</span>).asInstanceOf[<span class="type">Comparable</span>[_]]</span><br><span class="line">  <span class="type">DataSourceUtils</span>.createHoodieRecord(gr,</span><br><span class="line">    orderingVal, keyGenerator.getKey(gr), parameters(<span class="type">PAYLOAD_CLASS_OPT_KEY</span>))</span><br><span class="line">&#125;).toJavaRDD()</span><br></pre></td></tr></table></figure>
<p>RDDに一度変換した後、mapメソッドで加工する。</p>
<p>まず、 <code>genericRecords</code>
の内容は以下のようなものが含まれる。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">result = &#123;GenericRecord[1]@27822&#125; </span><br><span class="line"> 0 = &#123;GenericData$Record@27827&#125; &quot;&#123;&quot;begin_lat&quot;: 0.09632451474505643, &quot;begin_lon&quot;: 0.8989273848550128, &quot;driver&quot;: &quot;driver-164&quot;, &quot;end_lat&quot;: 0.6431885917325862, &quot;end_lon&quot;: 0.6664889106258252, &quot;fare&quot;: 86.865568091804, &quot;partitionpath&quot;: &quot;americas/brazil/sao_paulo&quot;, &quot;rider&quot;: &quot;rider-164&quot;, &quot;ts&quot;: 0.0, &quot;uuid&quot;: &quot;5d49cfb5-0db4-4172-bff4-e581eb1f9783&quot;&#125;&quot;</span><br><span class="line">  schema = &#123;Schema$RecordSchema@27835&#125; &quot;&#123;&quot;type&quot;:&quot;record&quot;,&quot;name&quot;:&quot;hudi_trips_cow_record&quot;,&quot;namespace&quot;:&quot;hoodie.hudi_trips_cow&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;begin_lat&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;begin_lon&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;driver&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;end_lat&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;end_lon&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;fare&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;partitionpath&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;rider&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;ts&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;uuid&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;]&#125;&quot;</span><br><span class="line">  values = &#123;Object[10]@27836&#125; </span><br><span class="line">   0 = &#123;Double@27838&#125; 0.09632451474505643</span><br><span class="line">   1 = &#123;Double@27839&#125; 0.8989273848550128</span><br><span class="line">   2 = &#123;Utf8@27840&#125; &quot;driver-164&quot;</span><br><span class="line">   3 = &#123;Double@27841&#125; 0.6431885917325862</span><br><span class="line">   4 = &#123;Double@27842&#125; 0.6664889106258252</span><br><span class="line">   5 = &#123;Double@27843&#125; 86.865568091804</span><br><span class="line">   6 = &#123;Utf8@27844&#125; &quot;americas/brazil/sao_paulo&quot;</span><br><span class="line">   7 = &#123;Utf8@27845&#125; &quot;rider-164&quot;</span><br><span class="line">   8 = &#123;Double@27846&#125; 0.0</span><br><span class="line">   9 = &#123;Utf8@27847&#125; &quot;5d49cfb5-0db4-4172-bff4-e581eb1f9783&quot;</span><br></pre></td></tr></table></figure>
<p>上記の通り、これは入ロクレコードそのものである。
その後、mapメソッドを使ってHudiで利用するキーを含む、Hudiのレコード形式に変換する。</p>
<p>変換された <code>hoodieAllIncomingRecords</code>
は以下のような内容になる。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">result = &#123;Wrappers$SeqWrapper@27881&#125;  size = 1</span><br><span class="line"> 0 = &#123;HoodieRecord@27883&#125; &quot;HoodieRecord&#123;key=HoodieKey &#123; recordKey=5d49cfb5-0db4-4172-bff4-e581eb1f9783 partitionPath=americas/brazil/sao_paulo&#125;, currentLocation=&apos;null&apos;, newLocation=&apos;null&apos;&#125;&quot;</span><br><span class="line">  key = &#123;HoodieKey@27892&#125; &quot;HoodieKey &#123; recordKey=5d49cfb5-0db4-4172-bff4-e581eb1f9783 partitionPath=americas/brazil/sao_paulo&#125;&quot;</span><br><span class="line">   recordKey = &quot;5d49cfb5-0db4-4172-bff4-e581eb1f9783&quot;</span><br><span class="line">   partitionPath = &quot;americas/brazil/sao_paulo&quot;</span><br><span class="line">  data = &#123;OverwriteWithLatestAvroPayload@27893&#125; </span><br><span class="line">   recordBytes = &#123;byte[142]@27895&#125; </span><br><span class="line">   orderingVal = &quot;0.0&quot;</span><br><span class="line">  currentLocation = null</span><br><span class="line">  newLocation = null</span><br><span class="line">  sealed = false</span><br></pre></td></tr></table></figure>
<p>上記の例の通り、ペイロードは
<code>org.apache.hudi.common.model.OverwriteWithLatestAvroPayload</code>
で保持される。</p>
<p>その後、いくつかモードの確認が行われた後、もしテーブルがなければ
<code>org.apache.hudi.common.table.HoodieTableMetaClient#initTableType</code>
を用いて テーブルを初期化する。</p>
<p>その後、重複レコードを必要に応じて落とす。</p>
<p>org/apache/hudi/HoodieSparkSqlWriter.scala:132</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> hoodieRecords =</span><br><span class="line">  <span class="keyword">if</span> (parameters(<span class="type">INSERT_DROP_DUPS_OPT_KEY</span>).toBoolean) &#123;</span><br><span class="line">    <span class="type">DataSourceUtils</span>.dropDuplicates(</span><br><span class="line">      jsc,</span><br><span class="line">      hoodieAllIncomingRecords,</span><br><span class="line">      mapAsJavaMap(parameters), client.getTimelineServer)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    hoodieAllIncomingRecords</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>レコードが空かどうかを改めて確認しつつ、 最後に書き込み実施。
<code>org.apache.hudi.DataSourceUtils#doWriteOperation</code>
が実態である。</p>
<p>org/apache/hudi/HoodieSparkSqlWriter.scala:147</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val writeStatuses = DataSourceUtils.doWriteOperation(client, hoodieRecords, commitTime, operation)</span><br></pre></td></tr></table></figure>
<p><code>org.apache.hudi.DataSourceUtils#doWriteOperation</code>
メソッドは以下の通り。</p>
<p>org/apache/hudi/DataSourceUtils.java:162</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> JavaRDD&lt;WriteStatus&gt; <span class="title">doWriteOperation</span><span class="params">(HoodieWriteClient client, JavaRDD&lt;HoodieRecord&gt; hoodieRecords,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    String commitTime, String operation)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (operation.equals(DataSourceWriteOptions.BULK_INSERT_OPERATION_OPT_VAL())) &#123;</span><br><span class="line">    <span class="keyword">return</span> client.bulkInsert(hoodieRecords, commitTime);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (operation.equals(DataSourceWriteOptions.INSERT_OPERATION_OPT_VAL())) &#123;</span><br><span class="line">    <span class="keyword">return</span> client.insert(hoodieRecords, commitTime);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// default is upsert</span></span><br><span class="line">    <span class="keyword">return</span> client.upsert(hoodieRecords, commitTime);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>今回の例だと、 <code>upseart</code> オペレーションなので
<code>org.apache.hudi.client.HoodieWriteClient#upsert</code>
メソッドが呼ばれる。 このメソッドは以下のとおりだが、ポイントは、
<code>org.apache.hudi.client.HoodieWriteClient#upsertRecordsInternal</code>
メソッドである。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> JavaRDD&lt;WriteStatus&gt; <span class="title">upsert</span><span class="params">(JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; records, <span class="keyword">final</span> String commitTime)</span> </span>&#123;</span><br><span class="line">  HoodieTable&lt;T&gt; table = getTableAndInitCtx(OperationType.UPSERT);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// De-dupe/merge if needed</span></span><br><span class="line">    JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; dedupedRecords =</span><br><span class="line">        combineOnCondition(config.shouldCombineBeforeUpsert(), records, config.getUpsertShuffleParallelism());</span><br><span class="line"></span><br><span class="line">    Timer.Context indexTimer = metrics.getIndexCtx();</span><br><span class="line">    <span class="comment">// perform index loop up to get existing location of records</span></span><br><span class="line">    JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; taggedRecords = getIndex().tagLocation(dedupedRecords, jsc, table);</span><br><span class="line">    metrics.updateIndexMetrics(LOOKUP_STR, metrics.getDurationInMs(indexTimer == <span class="keyword">null</span> ? <span class="number">0L</span> : indexTimer.stop()));</span><br><span class="line">    <span class="keyword">return</span> upsertRecordsInternal(taggedRecords, commitTime, table, <span class="keyword">true</span>);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (e <span class="keyword">instanceof</span> HoodieUpsertException) &#123;</span><br><span class="line">      <span class="keyword">throw</span> (HoodieUpsertException) e;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HoodieUpsertException(<span class="string">"Failed to upsert for commit time "</span> + commitTime, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>org.apache.hudi.client.HoodieWriteClient#upsertRecordsInternal</code>
メソッド内のポイントは、 以下の箇所。
<code>org.apache.spark.api.java.AbstractJavaRDDLike#mapPartitionsWithIndex</code>
メソッドで、upsertやinsertの処理を定義している。</p>
<p>org/apache/hudi/client/HoodieWriteClient.java:470</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;WriteStatus&gt; writeStatusRDD = partitionedRecords.mapPartitionsWithIndex((partition, recordItr) -&gt; &#123;</span><br><span class="line">  <span class="keyword">if</span> (isUpsert) &#123;</span><br><span class="line">    <span class="keyword">return</span> hoodieTable.handleUpsertPartition(commitTime, partition, recordItr, partitioner);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> hoodieTable.handleInsertPartition(commitTime, partition, recordItr, partitioner);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;, <span class="keyword">true</span>).flatMap(List::iterator);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> updateIndexAndCommitIfNeeded(writeStatusRDD, hoodieTable, commitTime);</span><br></pre></td></tr></table></figure>
<p>ここでは、
<code>org.apache.hudi.table.HoodieCopyOnWriteTable#handleUpsertPartition</code>
メソッドを確認してみる。</p>
<p>org/apache/hudi/table/HoodieCopyOnWriteTable.java:253</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleUpsertPartition(String commitTime, Integer partition, Iterator recordItr,</span><br><span class="line">    Partitioner partitioner) &#123;</span><br><span class="line">  UpsertPartitioner upsertPartitioner = (UpsertPartitioner) partitioner;</span><br><span class="line">  BucketInfo binfo = upsertPartitioner.getBucketInfo(partition);</span><br><span class="line">  BucketType btype = binfo.bucketType;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (btype.equals(BucketType.INSERT)) &#123;</span><br><span class="line">      <span class="keyword">return</span> handleInsert(commitTime, binfo.fileIdPrefix, recordItr);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (btype.equals(BucketType.UPDATE)) &#123;</span><br><span class="line">      <span class="keyword">return</span> handleUpdate(commitTime, binfo.fileIdPrefix, recordItr);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> HoodieUpsertException(<span class="string">"Unknown bucketType "</span> + btype + <span class="string">" for partition :"</span> + partition);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    String msg = <span class="string">"Error upserting bucketType "</span> + btype + <span class="string">" for partition :"</span> + partition;</span><br><span class="line">    LOG.error(msg, t);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HoodieUpsertException(msg, t);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>真ん中あたりに、INSERTかUPDATEかで条件分岐しているが、ここでは例としてINSERT側を確認する。
<code>org.apache.hudi.table.HoodieCopyOnWriteTable#handleInsert</code>
メソッドがポイントとなる。
なお、当該メッソッドには同期的な実装と、非同期的な実装があるよう。
ここでは上記呼び出しに基づき、非同期的な実装の方を確認する。</p>
<p>org/apache/hudi/table/HoodieCopyOnWriteTable.java:233</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleInsert(String commitTime, String idPfx, Iterator&lt;HoodieRecord&lt;T&gt;&gt; recordItr)</span><br><span class="line">    <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="comment">// This is needed since sometimes some buckets are never picked in getPartition() and end up with 0 records</span></span><br><span class="line">  <span class="keyword">if</span> (!recordItr.hasNext()) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Empty partition"</span>);</span><br><span class="line">    <span class="keyword">return</span> Collections.singletonList((List&lt;WriteStatus&gt;) Collections.EMPTY_LIST).iterator();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> CopyOnWriteLazyInsertIterable&lt;&gt;(recordItr, config, commitTime, <span class="keyword">this</span>, idPfx);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>戻り値が、
<code>org.apache.hudi.execution.CopyOnWriteLazyInsertIterable</code>
クラスのインスタンスになっていることがわかる。 このイテレータは、
<code>org.apache.hudi.client.utils.LazyIterableIterator</code>
アブストラクトクラスを継承している。
<code>org.apache.hudi.client.utils.LazyIterableIterator</code>
では、nextメソッドが</p>
<p>org/apache/hudi/client/utils/LazyIterableIterator.java:116</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> O <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> computeNext();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(ex);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>のように定義されており、実態が
<code>org.apache.hudi.client.utils.LazyIterableIterator#computeNext</code>
であることがわかる。 当該メソッドは、
<code>org.apache.hudi.execution.CopyOnWriteLazyInsertIterable#CopyOnWriteLazyInsertIterable</code>
クラスではオーバーライドされており、 以下のように定義されている。</p>
<p>org/apache/hudi/execution/CopyOnWriteLazyInsertIterable.java:93</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> List&lt;WriteStatus&gt; <span class="title">computeNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Executor service used for launching writer thread.</span></span><br><span class="line">  BoundedInMemoryExecutor&lt;HoodieRecord&lt;T&gt;, HoodieInsertValueGenResult&lt;HoodieRecord&gt;, List&lt;WriteStatus&gt;&gt; bufferedIteratorExecutor =</span><br><span class="line">      <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> Schema schema = <span class="keyword">new</span> Schema.Parser().parse(hoodieConfig.getSchema());</span><br><span class="line">    bufferedIteratorExecutor =</span><br><span class="line">        <span class="keyword">new</span> SparkBoundedInMemoryExecutor&lt;&gt;(hoodieConfig, inputItr, getInsertHandler(), getTransformFunction(schema));</span><br><span class="line">    <span class="keyword">final</span> List&lt;WriteStatus&gt; result = bufferedIteratorExecutor.execute();</span><br><span class="line">    <span class="keyword">assert</span> result != <span class="keyword">null</span> &amp;&amp; !result.isEmpty() &amp;&amp; !bufferedIteratorExecutor.isRemaining();</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HoodieException(e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> != bufferedIteratorExecutor) &#123;</span><br><span class="line">      bufferedIteratorExecutor.shutdownNow();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>どうやら内部でFutureパターンを利用し、非同期化して書き込みを行っているようだ。（これが筋よしなのかどうかは要議論。update、つまりマージも同様になっている。）
処理内容を知る上でポイントとなるのは、</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bufferedIteratorExecutor =</span><br><span class="line">    <span class="keyword">new</span> SparkBoundedInMemoryExecutor&lt;&gt;(hoodieConfig, inputItr, getInsertHandler(), getTransformFunction(schema));</span><br></pre></td></tr></table></figure>
<p>の箇所。
<code>org.apache.hudi.execution.CopyOnWriteLazyInsertIterable#getInsertHandler</code>
あたり。 中で用いられている、
<code>org.apache.hudi.execution.CopyOnWriteLazyInsertIterable.CopyOnWriteInsertHandler</code>
クラスがポイントとなる。
このクラスは、書き込みデータのキュー（要確認）からレコードを受け取って、処理していると考えられる。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">consumeOneRecord</span><span class="params">(HoodieInsertValueGenResult&lt;HoodieRecord&gt; payload)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> HoodieRecord insertPayload = payload.record;</span><br><span class="line">  <span class="comment">// lazily initialize the handle, for the first time</span></span><br><span class="line">  <span class="keyword">if</span> (handle == <span class="keyword">null</span>) &#123;</span><br><span class="line">    handle = <span class="keyword">new</span> HoodieCreateHandle(hoodieConfig, commitTime, hoodieTable, insertPayload.getPartitionPath(),</span><br><span class="line">        getNextFileId(idPrefix));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (handle.canWrite(payload.record)) &#123;</span><br><span class="line">    <span class="comment">// write the payload, if the handle has capacity</span></span><br><span class="line">    handle.write(insertPayload, payload.insertValue, payload.exception);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// handle is full.</span></span><br><span class="line">    statuses.add(handle.close());</span><br><span class="line">    <span class="comment">// Need to handle the rejected payload &amp; open new handle</span></span><br><span class="line">    handle = <span class="keyword">new</span> HoodieCreateHandle(hoodieConfig, commitTime, hoodieTable, insertPayload.getPartitionPath(),</span><br><span class="line">        getNextFileId(idPrefix));</span><br><span class="line">    handle.write(insertPayload, payload.insertValue, payload.exception); <span class="comment">// we should be able to write 1 payload.</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下の方にある <code>org.apache.hudi.io.HoodieCreateHandle</code>
クラスを用いているあたりがポイント。 そのwriteメソッドは以下の通り。
<code>org.apache.hudi.io.storage.HoodieStorageWriter#writeAvroWithMetadata</code>
を用いて書き出しているように見える。 （実際には
<code>org.apache.hudi.io.storage.HoodieParquetWriter</code> ）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(HoodieRecord record, Option&lt;IndexedRecord&gt; avroRecord)</span> </span>&#123;</span><br><span class="line">  Option recordMetadata = record.getData().getMetadata();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (avroRecord.isPresent()) &#123;</span><br><span class="line">      <span class="comment">// Convert GenericRecord to GenericRecord with hoodie commit metadata in schema</span></span><br><span class="line">      IndexedRecord recordWithMetadataInSchema = rewriteRecord((GenericRecord) avroRecord.get());</span><br><span class="line">      storageWriter.writeAvroWithMetadata(recordWithMetadataInSchema, record);</span><br><span class="line">      <span class="comment">// update the new location of record, so we know where to find it next</span></span><br><span class="line">      record.unseal();</span><br><span class="line">      record.setNewLocation(<span class="keyword">new</span> HoodieRecordLocation(instantTime, writeStatus.getFileId()));</span><br><span class="line">      record.seal();</span><br><span class="line">      recordsWritten++;</span><br><span class="line">      insertRecordsWritten++;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      recordsDeleted++;</span><br><span class="line">    &#125;</span><br><span class="line">    writeStatus.markSuccess(record, recordMetadata);</span><br><span class="line">    <span class="comment">// deflate record payload after recording success. This will help users access payload as a</span></span><br><span class="line">    <span class="comment">// part of marking</span></span><br><span class="line">    <span class="comment">// record successful.</span></span><br><span class="line">    record.deflate();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    <span class="comment">// Not throwing exception from here, since we don't want to fail the entire job</span></span><br><span class="line">    <span class="comment">// for a single record</span></span><br><span class="line">    writeStatus.markFailure(record, t, recordMetadata);</span><br><span class="line">    LOG.error(<span class="string">"Error writing record "</span> + record, t);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>org.apache.hudi.io.storage.HoodieParquetWriter#writeAvroWithMetadata</code>
メソッドは以下の通りである。 つまり、
<code>org.apache.parquet.hadoop.ParquetWriter#write</code>
を用いてParquet内に、Avroレコードを書き出していることがわかる。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeAvroWithMetadata</span><span class="params">(R avroRecord, HoodieRecord record)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  String seqId =</span><br><span class="line">      HoodieRecord.generateSequenceId(commitTime, TaskContext.getPartitionId(), recordIndex.getAndIncrement());</span><br><span class="line">  HoodieAvroUtils.addHoodieKeyToRecord((GenericRecord) avroRecord, record.getRecordKey(), record.getPartitionPath(),</span><br><span class="line">      file.getName());</span><br><span class="line">  HoodieAvroUtils.addCommitMetadataToRecord((GenericRecord) avroRecord, commitTime, seqId);</span><br><span class="line">  <span class="keyword">super</span>.write(avroRecord);</span><br><span class="line">  writeSupport.add(record.getRecordKey());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>今回のクイックスタートの例では、 <code>avroRecord</code>
には以下のような内容が含まれていた。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">result = &#123;GenericData$Record@18566&#125; &quot;&#123;&quot;_hoodie_commit_time&quot;: &quot;20200331002133&quot;, &quot;_hoodie_commit_seqno&quot;: &quot;20200331002133_0_44&quot;, &quot;_hoodie_record_key&quot;: &quot;7b887fb5-2837-4cac-b075-a8a8450f453d&quot;, &quot;_hoodie_partition_path&quot;: &quot;asia/india/chennai&quot;, &quot;_hoodie_file_name&quot;: &quot;317a54b0-70b8-4bdc-bfde-12ba4fde982b-0_0-207-301_20200331002133.parquet&quot;, &quot;begin_lat&quot;: 0.4789745387904072, &quot;begin_lon&quot;: 0.14781856144057215, &quot;driver&quot;: &quot;driver-022&quot;, &quot;end_lat&quot;: 0.10509642405359532, &quot;end_lon&quot;: 0.07682825311613706, &quot;fare&quot;: 30.429177017810616, &quot;partitionpath&quot;: &quot;asia/india/chennai&quot;, &quot;rider&quot;: &quot;rider-022&quot;, &quot;ts&quot;: 0.0, &quot;uuid&quot;: &quot;7b887fb5-2837-4cac-b075-a8a8450f453d&quot;&#125;&quot;</span><br><span class="line"> schema = &#123;Schema$RecordSchema@18582&#125; &quot;&#123;&quot;type&quot;:&quot;record&quot;,&quot;name&quot;:&quot;hudi_trips_cow_record&quot;,&quot;namespace&quot;:&quot;hoodie.hudi_trips_cow&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;_hoodie_commit_time&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;doc&quot;:&quot;&quot;,&quot;default&quot;:null&#125;,&#123;&quot;name&quot;:&quot;_hoodie_commit_seqno&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;doc&quot;:&quot;&quot;,&quot;default&quot;:null&#125;,&#123;&quot;name&quot;:&quot;_hoodie_record_key&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;doc&quot;:&quot;&quot;,&quot;default&quot;:null&#125;,&#123;&quot;name&quot;:&quot;_hoodie_partition_path&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;doc&quot;:&quot;&quot;,&quot;default&quot;:null&#125;,&#123;&quot;name&quot;:&quot;_hoodie_file_name&quot;,&quot;type&quot;:[&quot;null&quot;,&quot;string&quot;],&quot;doc&quot;:&quot;&quot;,&quot;default&quot;:null&#125;,&#123;&quot;name&quot;:&quot;begin_lat&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;begin_lon&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;driver&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;end_lat&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;end_lon&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;fare&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;partitionpath&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;rider&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;ts&quot;,&quot;type&quot;:[&quot;double&quot;,&quot;null&quot;]&#125;,&#123;&quot;name&quot;:&quot;uuid&quot;,&quot;type&quot;:[&quot;string&quot;,&quot;null&quot;]&#125;]&#125;&quot;</span><br><span class="line"> values = &#123;Object[15]@18583&#125; </span><br><span class="line">  0 = &quot;20200331002133&quot;</span><br><span class="line">  1 = &quot;20200331002133_0_44&quot;</span><br><span class="line">  2 = &quot;7b887fb5-2837-4cac-b075-a8a8450f453d&quot;</span><br><span class="line">  3 = &quot;asia/india/chennai&quot;</span><br><span class="line">  4 = &quot;317a54b0-70b8-4bdc-bfde-12ba4fde982b-0_0-207-301_20200331002133.parquet&quot;</span><br><span class="line">  5 = &#123;Double@18596&#125; 0.4789745387904072</span><br><span class="line">  6 = &#123;Double@18597&#125; 0.14781856144057215</span><br><span class="line">  7 = &#123;Utf8@18598&#125; &quot;driver-022&quot;</span><br><span class="line">  8 = &#123;Double@18599&#125; 0.10509642405359532</span><br><span class="line">  9 = &#123;Double@18600&#125; 0.07682825311613706</span><br><span class="line">  10 = &#123;Double@18601&#125; 30.429177017810616</span><br><span class="line">  11 = &#123;Utf8@18602&#125; &quot;asia/india/chennai&quot;</span><br><span class="line">  12 = &#123;Utf8@18603&#125; &quot;rider-022&quot;</span><br><span class="line">  13 = &#123;Double@18604&#125; 0.0</span><br><span class="line">  14 = &#123;Utf8@18605&#125; &quot;7b887fb5-2837-4cac-b075-a8a8450f453d&quot;</span><br></pre></td></tr></table></figure>
<h3><span id="orgapachehudidefaultsourcecreaterelation読み込み">org.apache.hudi.DefaultSource#createRelation（読み込み）</span></h3>
<p>当該メソッドのポイントを確認する。</p>
<p><code>hoodie.datasource.query.type</code>
の種類によって返すRelationが変わる。</p>
<p>org/apache/hudi/DefaultSource.scala:60</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (parameters(<span class="type">QUERY_TYPE_OPT_KEY</span>).equals(<span class="type">QUERY_TYPE_SNAPSHOT_OPT_VAL</span>)) &#123;</span><br><span class="line"></span><br><span class="line">(snip)</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (parameters(<span class="type">QUERY_TYPE_OPT_KEY</span>).equals(<span class="type">QUERY_TYPE_INCREMENTAL_OPT_VAL</span>)) &#123;</span><br><span class="line"></span><br><span class="line">(snip)</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">HoodieException</span>(<span class="string">"Invalid query type :"</span> + parameters(<span class="type">QUERY_TYPE_OPT_KEY</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上記の通り、 <code>snapshot</code> 、もしくは
<code>incremental</code> クエリタイプである。 なお、以下の通り、
<code>MERGE_ON_READ</code> テーブルに対する <code>snapshot</code>
クエリタイプは利用できない。 もし使いたければ、SparkのData
Source機能ではなく、Hiveテーブルとして読み込むこと。</p>
<p>org/apache/hudi/DefaultSource.scala:69</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log.warn(<span class="string">"Snapshot view not supported yet via data source, for MERGE_ON_READ tables. "</span> +</span><br><span class="line">  <span class="string">"Please query the Hive table registered using Spark SQL."</span>)</span><br></pre></td></tr></table></figure>
<p>まずクエリタイプが <code>snapshot</code> である場合は、
以下の通り、Parquetとして読み込みが定義され、Relationが返される。</p>
<p>org/apache/hudi/DefaultSource.scala:72</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataSource</span>.apply(</span><br><span class="line">  sparkSession = sqlContext.sparkSession,</span><br><span class="line">  userSpecifiedSchema = <span class="type">Option</span>(schema),</span><br><span class="line">  className = <span class="string">"parquet"</span>,</span><br><span class="line">  options = parameters)</span><br><span class="line">  .resolveRelation()</span><br></pre></td></tr></table></figure>
<p>例えば、クイックスタートの例</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> tripsSnapshotDF = spark.</span><br><span class="line">         read.</span><br><span class="line">         format(<span class="string">"hudi"</span>).</span><br><span class="line">         load(basePath + <span class="string">"/*/*/*/*"</span>)</span><br><span class="line">scala&gt; tripsSnapshotDF.createOrReplaceTempView(<span class="string">"hudi_trips_snapshot"</span>)</span><br></pre></td></tr></table></figure>
<p>では、こちらのタイプ。
ParquetベースのRelation（実際には、HadoopFsRelation）が返される。
上記の例では、当該RelationのrootPathsに、以下のような値が含まれる。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rootPaths = &#123;$colon$colon@14885&#125; &quot;::&quot; size = 6</span><br><span class="line"> 0 = &#123;Path@15421&#125; &quot;file:/tmp/hudi_trips_cow/americas/brazil/sao_paulo/ae28c85a-38f0-487f-a42d-3a0babc9d321-0_0-21-25_20200329002247.parquet&quot;</span><br><span class="line"> 1 = &#123;Path@15422&#125; &quot;file:/tmp/hudi_trips_cow/americas/brazil/sao_paulo/.hoodie_partition_metadata&quot;</span><br><span class="line"> 2 = &#123;Path@15423&#125; &quot;file:/tmp/hudi_trips_cow/americas/united_states/san_francisco/849db286-1cbe-4a1f-b544-9939893e99f8-0_1-21-26_20200329002247.parquet&quot;</span><br><span class="line"> 3 = &#123;Path@15424&#125; &quot;file:/tmp/hudi_trips_cow/americas/united_states/san_francisco/.hoodie_partition_metadata&quot;</span><br><span class="line"> 4 = &#123;Path@15425&#125; &quot;file:/tmp/hudi_trips_cow/asia/india/chennai/2ebfbab0-4f8f-42db-b79e-1c0cbcc3cf39-0_2-21-27_20200329002247.parquet&quot;</span><br><span class="line"> 5 = &#123;Path@15426&#125; &quot;file:/tmp/hudi_trips_cow/asia/india/chennai/.hoodie_partition_metadata&quot;</span><br></pre></td></tr></table></figure>
<p>次にクエリタイプが <code>incremental</code> である場合は、
以下の通り、
<code>org.apache.hudi.IncrementalRelation#IncrementalRelation</code>
が返される。</p>
<p>org/apache/hudi/DefaultSource.scala:79</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">IncrementalRelation</span>(sqlContext, path.get, optParams, schema)</span><br></pre></td></tr></table></figure>
<p>クイックスタートの例</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> tripsIncrementalDF = spark.read.format(<span class="string">"hudi"</span>).</span><br><span class="line">         option(<span class="type">QUERY_TYPE_OPT_KEY</span>, <span class="type">QUERY_TYPE_INCREMENTAL_OPT_VAL</span>).</span><br><span class="line">         option(<span class="type">BEGIN_INSTANTTIME_OPT_KEY</span>, beginTime).</span><br><span class="line">         load(basePath)</span><br><span class="line">scala&gt; tripsIncrementalDF.createOrReplaceTempView(<span class="string">"hudi_trips_incremental"</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">"select `_hoodie_commit_time`, fare, begin_lon, begin_lat, ts from  hudi_trips_incremental where fare &gt; 20.0"</span>).show()</span><br></pre></td></tr></table></figure>
<p>では、
<code>org.apache.hudi.IncrementalRelation#IncrementalRelation</code>
が戻り値として返される。</p>
<h3><span id="incrementalrelation">IncrementalRelation</span></h3>
<h4><span id="コンストラクタ">コンストラクタ</span></h4>
<p>Parquetをファイルを単純に読めば良いのと比べて、格納された最新データを返すようにしないとならないので
それなりに複雑なRelationとなっている。</p>
<p>以下、簡単にコンストラクタのポイントを確認する。</p>
<p>最初にメタデータを取得するクライアント。
コミット、セーブポイント、コンパクションなどの情報を得られるようになる。</p>
<p>org/apache/hudi/IncrementalRelation.scala:51</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> metaClient = <span class="keyword">new</span> <span class="type">HoodieTableMetaClient</span>(sqlContext.sparkContext.hadoopConfiguration, basePath, <span class="literal">true</span>)</span><br></pre></td></tr></table></figure>
<p>クイックスタートの例では、 <code>metaPath</code> は、
<code>file:/tmp/hudi_trips_cow/.hoodie</code> だった。</p>
<p>続いてテーブル情報のインスタンスを取得する。
テーブル情報からタイムラインを取り出す。</p>
<p>org/apache/hudi/IncrementalRelation.scala:57</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> hoodieTable = <span class="type">HoodieTable</span>.getHoodieTable(metaClient, <span class="type">HoodieWriteConfig</span>.newBuilder().withPath(basePath).build(),</span><br><span class="line">  sqlContext.sparkContext)</span><br><span class="line"><span class="keyword">val</span> commitTimeline = hoodieTable.getMetaClient.getCommitTimeline.filterCompletedInstants()</span><br><span class="line"><span class="keyword">if</span> (commitTimeline.empty()) &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">HoodieException</span>(<span class="string">"No instants to incrementally pull"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (!optParams.contains(<span class="type">DataSourceReadOptions</span>.<span class="type">BEGIN_INSTANTTIME_OPT_KEY</span>)) &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">HoodieException</span>(<span class="string">s"Specify the begin instant time to pull from using "</span> +</span><br><span class="line">    <span class="string">s"option <span class="subst">$&#123;DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY&#125;</span>"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>クイックスタートの例で実際に生成されたタイムラインは以下の通り。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">instants = &#123;ArrayList@25586&#125;  size = 3</span><br><span class="line"> 0 = &#123;HoodieInstant@25589&#125; &quot;[20200330002239__commit__COMPLETED]&quot;</span><br><span class="line"> 1 = &#123;HoodieInstant@25590&#125; &quot;[20200330002354__commit__COMPLETED]&quot;</span><br><span class="line"> 2 = &#123;HoodieInstant@25591&#125; &quot;[20200330003142__commit__COMPLETED]&quot;</span><br></pre></td></tr></table></figure>
<p>オプションとして与えられた「はじめ」と「おわり」から、
対象となるタイムラインを構成する。
タイムライン上、最も新しいインスタンスを取得し、
Parquetファイルからスキーマを読んでいる。</p>
<p>org/apache/hudi/IncrementalRelation.scala:68</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lastInstant = commitTimeline.lastInstant().get()</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> commitsToReturn = commitTimeline.findInstantsInRange(</span><br><span class="line">  optParams(<span class="type">DataSourceReadOptions</span>.<span class="type">BEGIN_INSTANTTIME_OPT_KEY</span>),</span><br><span class="line">  optParams.getOrElse(<span class="type">DataSourceReadOptions</span>.<span class="type">END_INSTANTTIME_OPT_KEY</span>, lastInstant.getTimestamp))</span><br><span class="line">  .getInstants.iterator().toList</span><br><span class="line"></span><br><span class="line"><span class="comment">// use schema from a file produced in the latest instant</span></span><br><span class="line"><span class="keyword">val</span> latestSchema = &#123;</span><br><span class="line">  <span class="comment">// use last instant if instant range is empty</span></span><br><span class="line">  <span class="keyword">val</span> instant = commitsToReturn.lastOption.getOrElse(lastInstant)</span><br><span class="line">  <span class="keyword">val</span> latestMeta = <span class="type">HoodieCommitMetadata</span></span><br><span class="line">        .fromBytes(commitTimeline.getInstantDetails(instant).get, classOf[<span class="type">HoodieCommitMetadata</span>])</span><br><span class="line">  <span class="keyword">val</span> metaFilePath = latestMeta.getFileIdAndFullPaths(basePath).values().iterator().next()</span><br><span class="line">  <span class="type">AvroConversionUtils</span>.convertAvroSchemaToStructType(<span class="type">ParquetUtils</span>.readAvroSchema(</span><br><span class="line">    sqlContext.sparkContext.hadoopConfiguration, <span class="keyword">new</span> <span class="type">Path</span>(metaFilePath)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>クイックスタートの例では、 <code>commitsToReturn</code>
は以下の通り。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result = &#123;$colon$colon@25626&#125; &quot;::&quot; size = 1</span><br><span class="line"> 0 = &#123;HoodieInstant@25591&#125; &quot;[20200330003142__commit__COMPLETED]&quot;</span><br><span class="line">  state = &#123;HoodieInstant$State@25602&#125; &quot;COMPLETED&quot;</span><br><span class="line">  action = &quot;commit&quot;</span><br><span class="line">  timestamp = &quot;20200330003142&quot;</span><br></pre></td></tr></table></figure>
<p>また、少々気になるのは、</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">AvroConversionUtils</span>.convertAvroSchemaToStructType(<span class="type">ParquetUtils</span>.readAvroSchema(</span><br><span class="line">  sqlContext.sparkContext.hadoopConfiguration, <span class="keyword">new</span> <span class="type">Path</span>(metaFilePath)))</span><br></pre></td></tr></table></figure>
<p>という箇所で、もともとParquet形式のデータからAvro形式のスキーマを取り出し、それをさらにSparkのStructTypeに変換しているところ。
実際にParquetのfooterから取り出したスキーマ情報を、AvroのSchemaに変換しているのは以下の箇所。</p>
<p>org/apache/hudi/common/util/ParquetUtils.java:140</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public static <span class="type">Schema</span> readAvroSchema(<span class="type">Configuration</span> configuration, <span class="type">Path</span> parquetFilePath) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">AvroSchemaConverter</span>().convert(readSchema(configuration, parquetFilePath));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Parquet自身にAvroへの変換器
<code>org.apache.parquet.avro.AvroSchemaConverter</code>
が備わっているので便利？</li>
<li>SparkのData
Source機能でDataFrame化してからスキーマを取り出すと、一度読み込みが生じていしまうから非効率？</li>
</ul>
<p>という理由が想像されるが、やや回りくどいような印象を持った。
★要確認</p>
<p>本編に戻る。続いてフィルタを定義。</p>
<p>org/apache/hudi/IncrementalRelation.scala:86</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> filters = &#123;</span><br><span class="line">  <span class="keyword">if</span> (optParams.contains(<span class="type">DataSourceReadOptions</span>.<span class="type">PUSH_DOWN_INCR_FILTERS_OPT_KEY</span>)) &#123;</span><br><span class="line">    <span class="keyword">val</span> filterStr = optParams.getOrElse(</span><br><span class="line">      <span class="type">DataSourceReadOptions</span>.<span class="type">PUSH_DOWN_INCR_FILTERS_OPT_KEY</span>,</span><br><span class="line">      <span class="type">DataSourceReadOptions</span>.<span class="type">DEFAULT_PUSH_DOWN_FILTERS_OPT_VAL</span>)</span><br><span class="line">    filterStr.split(<span class="string">","</span>).filter(!_.isEmpty)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">Array</span>[<span class="type">String</span>]()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ここまでがコンストラクタ。</p>
<h4><span id="buildscan">buildScan</span></h4>
<p>実際にSparkのData
Sourceで読み込むときに用いられる読み込みの手段が定義されている。
以下にポイントを述べる。</p>
<p>org/apache/hudi/IncrementalRelation.scala:99</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">buildScan</span></span>(): <span class="type">RDD</span>[<span class="type">Row</span>] = &#123;</span><br><span class="line"></span><br><span class="line">(snip)</span><br></pre></td></tr></table></figure>
<p>ファイルIDとフルPATHのマップを作る。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> fileIdToFullPath = mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line"><span class="keyword">for</span> (commit &lt;- commitsToReturn) &#123;</span><br><span class="line">  <span class="keyword">val</span> metadata: <span class="type">HoodieCommitMetadata</span> = <span class="type">HoodieCommitMetadata</span>.fromBytes(commitTimeline.getInstantDetails(commit)</span><br><span class="line">    .get, classOf[<span class="type">HoodieCommitMetadata</span>])</span><br><span class="line">  fileIdToFullPath ++= metadata.getFileIdAndFullPaths(basePath).toMap</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上記マップに対し、必要に応じてフィルタを適用する。</p>
<p>org/apache/hudi/IncrementalRelation.scala:106</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> pathGlobPattern = optParams.getOrElse(</span><br><span class="line">  <span class="type">DataSourceReadOptions</span>.<span class="type">INCR_PATH_GLOB_OPT_KEY</span>,</span><br><span class="line">  <span class="type">DataSourceReadOptions</span>.<span class="type">DEFAULT_INCR_PATH_GLOB_OPT_VAL</span>)</span><br><span class="line"><span class="keyword">val</span> filteredFullPath = <span class="keyword">if</span>(!pathGlobPattern.equals(<span class="type">DataSourceReadOptions</span>.<span class="type">DEFAULT_INCR_PATH_GLOB_OPT_VAL</span>)) &#123;</span><br><span class="line">  <span class="keyword">val</span> globMatcher = <span class="keyword">new</span> <span class="type">GlobPattern</span>(<span class="string">"*"</span> + pathGlobPattern)</span><br><span class="line">  fileIdToFullPath.filter(p =&gt; globMatcher.matches(p._2))</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  fileIdToFullPath</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>コンストラクタで定義されたフィルタを適用しながら、
対象となるParquetファイルを読み込み、RDDを生成する。</p>
<p>org/apache/hudi/IncrementalRelation.scala:117</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.sparkContext.hadoopConfiguration.unset(<span class="string">"mapreduce.input.pathFilter.class"</span>)</span><br><span class="line"><span class="keyword">val</span> sOpts = optParams.filter(p =&gt; !p._1.equalsIgnoreCase(<span class="string">"path"</span>))</span><br><span class="line"><span class="keyword">if</span> (filteredFullPath.isEmpty) &#123;</span><br><span class="line">  sqlContext.sparkContext.emptyRDD[<span class="type">Row</span>]</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  log.info(<span class="string">"Additional Filters to be applied to incremental source are :"</span> + filters)</span><br><span class="line">  filters.foldLeft(sqlContext.read.options(sOpts)</span><br><span class="line">    .schema(latestSchema)</span><br><span class="line">    .parquet(filteredFullPath.values.toList: _*)</span><br><span class="line">    .filter(<span class="type">String</span>.format(<span class="string">"%s &gt;= '%s'"</span>, <span class="type">HoodieRecord</span>.<span class="type">COMMIT_TIME_METADATA_FIELD</span>, commitsToReturn.head.getTimestamp))</span><br><span class="line">    .filter(<span class="type">String</span>.format(<span class="string">"%s &lt;= '%s'"</span>,</span><br><span class="line">      <span class="type">HoodieRecord</span>.<span class="type">COMMIT_TIME_METADATA_FIELD</span>, commitsToReturn.last.getTimestamp)))((e, f) =&gt; e.filter(f))</span><br><span class="line">    .toDF().rdd</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1><span id="hudiへの書き込み">Hudiへの書き込み</span></h1>
<p><a href="https://hudi.apache.org/docs/writing_data.html" target="_blank" rel="noopener">Writing Hudi
Tables</a> をベースに調べる。</p>
<h2><span id="オペレーション種類">オペレーション種類</span></h2>
<p>書き込みのオペレーション種類は、upsert、insert、bulk_insert。
クイックスタートにはbulk_insertはなかった。</p>
<h2><span id="deltastreamer">DeltaStreamer</span></h2>
<p>ユーティリティとして付属するDeltaStreamerを用いると、
Kafka等からデータを取り込める。
Avro等のスキーマのデータを読み取れる。</p>
<h3><span id="動作確認">動作確認</span></h3>
<h4><span id="パッケージ化">パッケージ化</span></h4>
<p><a href="https://hudi.apache.org/docs/writing_data.html#deltastreamer" target="_blank" rel="noopener">公式ドキュメントのData
Streamer</a> の手順に基づくと、
ビルドされたユーティリティを使うことになるので、
予めパッケージ化しておく。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir -p ~/Sources</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ~/Sources</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/apache/incubator-hudi.git incubator-hudi-052</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> incubator-hudi-052</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout -b release-0.5.2-incubating refs/tags/release-0.5.2-incubating</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mvn clean package -DskipTests -DskipITs</span></span><br></pre></td></tr></table></figure>
<h4><span id="実行">実行</span></h4>
<p><a href="https://hudi.apache.org/docs/writing_data.html#deltastreamer" target="_blank" rel="noopener">公式ドキュメントのData
Streamer</a>に基づくと、Confluentメンバが作成した （ <a href="https://github.com/apurvam/streams-prototyping" target="_blank" rel="noopener">apurvam
streams-prototyping</a> ）サンプルデータ作成用のAvroスキーマと Confluent
PlatformのKSQLのユーティリティを 使ってサンプルデータを作成する。</p>
<p>ついては。予めConfluent Platformをインストールしておくこと。</p>
<p>まずはスキーマをダウンロードする。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> curl https://raw.githubusercontent.com/apurvam/streams-prototyping/master/src/main/resources/impressions.avro &gt; /tmp/impressions.avro</span></span><br></pre></td></tr></table></figure>
<p>テストデータを生成する。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ksql-datagen schema=/tmp/impressions.avro format=avro topic=impressions key=impressionid</span></span><br></pre></td></tr></table></figure>
<p>別の端末を開き、ユーティリティを起動する。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> SPARK_HOME=/opt/spark/default</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ~/Sources/incubator-hudi-052</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-submit --class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer packaging/hudi-utilities-bundle/target/hudi-utilities-bundle_2.11-0.5.2-incubating.jar \</span></span><br><span class="line">  --props file://$&#123;PWD&#125;/hudi-utilities/src/test/resources/delta-streamer-config/kafka-source.properties \</span><br><span class="line">  --schemaprovider-class org.apache.hudi.utilities.schema.SchemaRegistryProvider \</span><br><span class="line">  --source-class org.apache.hudi.utilities.sources.AvroKafkaSource \</span><br><span class="line">  --source-ordering-field impresssiontime \</span><br><span class="line">  --target-base-path file:\/\/\/tmp/hudi-deltastreamer-op \</span><br><span class="line">  --target-table uber.impressions \</span><br><span class="line">  --table-type COPY_ON_WRITE \</span><br><span class="line">  --op BULK_INSERT</span><br></pre></td></tr></table></figure>
<p>なお、 <a href="https://hudi.apache.org/docs/writing_data.html#deltastreamer" target="_blank" rel="noopener">公式ドキュメントのData
Streamer</a> から2箇所修正した。（JarファイルPATH、
<code>--table-type</code> オプション追加。</p>
<p>Kafkaから読み込んで書き出したデータ（
<code>/tmp/hudi-deltastreamer-op</code> ）を確認してみる。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="variable">$&#123;SPARK_HOME&#125;</span>/bin/spark-shell \</span></span><br><span class="line">  --packages org.apache.hudi:hudi-spark-bundle_2.11:0.5.2-incubating,org.apache.spark:spark-avro_2.11:2.4.5 \</span><br><span class="line">  --conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer'</span><br></pre></td></tr></table></figure>
<p>シェルが起動したら、以下の通り読み込んで見る。 なお、ここでは
<code>userid</code>
がパーティションキーとなっているので、ロード時にそれを指定した。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> basePath = <span class="string">"file:///tmp/hudi-deltastreamer-op"</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> impressionDF = spark.</span><br><span class="line">         read.</span><br><span class="line">         format(<span class="string">"hudi"</span>).</span><br><span class="line">         load(basePath + <span class="string">"/*/*"</span>)</span><br></pre></td></tr></table></figure>
<p>内容は以下の通り。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; impressionDF.show</span><br><span class="line">+-------------------+--------------------+------------------+----------------------+--------------------+---------------+--------------+-------+-----+</span><br><span class="line">|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|impresssiontime|  impressionid| userid| adid|</span><br><span class="line">+-------------------+--------------------+------------------+----------------------+--------------------+---------------+--------------+-------+-----+</span><br><span class="line">|     <span class="number">20200406002420</span>|<span class="number">20200406002420</span>_1_...|    impression_106|               user_83|fb381e12-f9ec<span class="number">-4</span>fb...|  <span class="number">1586096500438</span>|impression_106|user_83|ad_57|</span><br><span class="line">|     <span class="number">20200406002420</span>|<span class="number">20200406002420</span>_1_...|    impression_107|               user_83|fb381e12-f9ec<span class="number">-4</span>fb...|  <span class="number">1586096464324</span>|impression_107|user_83|ad_11|</span><br><span class="line">|     <span class="number">20200406002420</span>|<span class="number">20200406002420</span>_1_...|    impression_111|               user_83|fb381e12-f9ec<span class="number">-4</span>fb...|  <span class="number">1586096366450</span>|impression_111|user_83|ad_14|</span><br><span class="line">|     <span class="number">20200406002420</span>|<span class="number">20200406002420</span>_1_...|    impression_111|               user_83|fb381e12-f9ec<span class="number">-4</span>fb...|  <span class="number">1586099019181</span>|impression_111|user_83|ad_38|</span><br><span class="line">|     <span class="number">20200406002420</span>|<span class="number">20200406002420</span>_1_...|    impression_116|               user_83|fb381e12-f9ec<span class="number">-4</span>fb...|  <span class="number">1586099146437</span>|impression_116|user_83|ad_48|</span><br><span class="line">|     <span class="number">20200406002420</span>|<span class="number">20200406002420</span>_1_...|    impression_121|               user_83|fb381e12-f9ec<span class="number">-4</span>fb...|  <span class="number">1586098316334</span>|impression_121|user_83|ad_26|</span><br><span class="line"></span><br><span class="line">(snip)</span><br></pre></td></tr></table></figure>
<h3><span id="実装確認">実装確認</span></h3>
<p><code>org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer</code>
クラスの実装を確認する。</p>
<p>まずmainは以下の通り。</p>
<p>org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java:298</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> Config cfg = <span class="keyword">new</span> Config();</span><br><span class="line">  JCommander cmd = <span class="keyword">new</span> JCommander(cfg, <span class="keyword">null</span>, args);</span><br><span class="line">  <span class="keyword">if</span> (cfg.help || args.length == <span class="number">0</span>) &#123;</span><br><span class="line">    cmd.usage();</span><br><span class="line">    System.exit(<span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Map&lt;String, String&gt; additionalSparkConfigs = SchedulerConfGenerator.getSparkSchedulingConfigs(cfg);</span><br><span class="line">  JavaSparkContext jssc =</span><br><span class="line">      UtilHelpers.buildSparkContext(<span class="string">"delta-streamer-"</span> + cfg.targetTableName, cfg.sparkMaster, additionalSparkConfigs);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">new</span> HoodieDeltaStreamer(cfg, jssc).sync();</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    jssc.stop();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上記の通り、
<code>org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer#sync</code>
メソッドがエントリポイント。</p>
<p>org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java:116</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sync</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (cfg.continuousMode) &#123;</span><br><span class="line">    deltaSyncService.start(<span class="keyword">this</span>::onDeltaSyncShutdown);</span><br><span class="line">    deltaSyncService.waitForShutdown();</span><br><span class="line">    LOG.info(<span class="string">"Delta Sync shutting down"</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    LOG.info(<span class="string">"Delta Streamer running only single round"</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      deltaSyncService.getDeltaSync().syncOnce();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">      LOG.error(<span class="string">"Got error running delta sync once. Shutting down"</span>, ex);</span><br><span class="line">      <span class="keyword">throw</span> ex;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      deltaSyncService.close();</span><br><span class="line">      LOG.info(<span class="string">"Shut down delta streamer"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上記の通り、 <code>continous</code>
モードかどうかで動作が変わる。</p>
<p>ここでは一旦、ワンショットの場合を確認する。</p>
<p>上記の通り、
<code>org.apache.hudi.utilities.deltastreamer.DeltaSync#syncOnce</code>
メソッドがエントリポイント。
当該メソッドは以下のようにシンプルな内容。</p>
<p>org/apache/hudi/utilities/deltastreamer/DeltaSync.java:218</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Option&lt;String&gt; <span class="title">syncOnce</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  Option&lt;String&gt; scheduledCompaction = Option.empty();</span><br><span class="line">  HoodieDeltaStreamerMetrics metrics = <span class="keyword">new</span> HoodieDeltaStreamerMetrics(getHoodieClientConfig(schemaProvider));</span><br><span class="line">  Timer.Context overallTimerContext = metrics.getOverallTimerContext();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Refresh Timeline</span></span><br><span class="line">  refreshTimeline();</span><br><span class="line"></span><br><span class="line">  Pair&lt;SchemaProvider, Pair&lt;String, JavaRDD&lt;HoodieRecord&gt;&gt;&gt; srcRecordsWithCkpt = readFromSource(commitTimelineOpt);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">null</span> != srcRecordsWithCkpt) &#123;</span><br><span class="line">    <span class="comment">// this is the first input batch. If schemaProvider not set, use it and register Avro Schema and start</span></span><br><span class="line">    <span class="comment">// compactor</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == schemaProvider) &#123;</span><br><span class="line">      <span class="comment">// Set the schemaProvider if not user-provided</span></span><br><span class="line">      <span class="keyword">this</span>.schemaProvider = srcRecordsWithCkpt.getKey();</span><br><span class="line">      <span class="comment">// Setup HoodieWriteClient and compaction now that we decided on schema</span></span><br><span class="line">      setupWriteClient();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    scheduledCompaction = writeToSink(srcRecordsWithCkpt.getRight().getRight(),</span><br><span class="line">        srcRecordsWithCkpt.getRight().getLeft(), metrics, overallTimerContext);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Clear persistent RDDs</span></span><br><span class="line">  jssc.getPersistentRDDs().values().forEach(JavaRDD::unpersist);</span><br><span class="line">  <span class="keyword">return</span> scheduledCompaction;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最初にメトリクスの準備、データソースから読み出してRDD化する定義（
<code>org.apache.hudi.utilities.deltastreamer.DeltaSync#readFromSource</code>
メソッド） その後、
<code>org.apache.hudi.utilities.deltastreamer.DeltaSync#writeToSink</code>
メソッドにより、定義されたRDDの内容を実際に書き込む。</p>
<p>ここでは上記メソッドを確認する。</p>
<p>まず与えられたRDDから重複排除する。</p>
<p>org/apache/hudi/utilities/deltastreamer/DeltaSync.java:352</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">private</span> Option&lt;String&gt; <span class="title">writeToSink</span><span class="params">(JavaRDD&lt;HoodieRecord&gt; records, String checkpointStr,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     HoodieDeltaStreamerMetrics metrics, Timer.Context overallTimerContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    Option&lt;String&gt; scheduledCompactionInstant = Option.empty();</span><br><span class="line">    <span class="comment">// filter dupes if needed</span></span><br><span class="line">    <span class="keyword">if</span> (cfg.filterDupes) &#123;</span><br><span class="line">      <span class="comment">// turn upserts to insert</span></span><br><span class="line">      cfg.operation = cfg.operation == Operation.UPSERT ? Operation.INSERT : cfg.operation;</span><br><span class="line">      records = DataSourceUtils.dropDuplicates(jssc, records, writeClient.getConfig());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> isEmpty = records.isEmpty();</span><br><span class="line"></span><br><span class="line">(snip)</span><br></pre></td></tr></table></figure>
<p>その後実際の書き込みになるが、そのとき採用したオペレーション種類によって動作が異なる。</p>
<p>org/apache/hudi/utilities/deltastreamer/DeltaSync.java:369</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (cfg.operation == Operation.INSERT) &#123;</span><br><span class="line">  writeStatusRDD = writeClient.insert(records, instantTime);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cfg.operation == Operation.UPSERT) &#123;</span><br><span class="line">  writeStatusRDD = writeClient.upsert(records, instantTime);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cfg.operation == Operation.BULK_INSERT) &#123;</span><br><span class="line">  writeStatusRDD = writeClient.bulkInsert(records, instantTime);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> HoodieDeltaStreamerException(<span class="string">"Unknown operation :"</span> + cfg.operation);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="bulkinsert">bulkInsert</span></h4>
<p>ここではためしに
<code>org.apache.hudi.client.HoodieWriteClient#bulkInsert</code>
メソッドを確認してみる。</p>
<p>当該メソッドでは、最初にCOPY_ON_WRITEかMERGE_ON_READかに応じて、それぞれの種類のテーブル情報を取得する。
その後、
<code>org.apache.hudi.client.HoodieWriteClient#bulkInsertInternal</code>
メソッドを使ってデータを書き込む。</p>
<p>なお、その間で重複排除されているが、上記の通り、もともと重複排除しているはずなので、要確認。（重複排除のロジックが異なるのかどうか、など）
パット見た感じ、
<code>org.apache.hudi.DataSourceUtils#dropDuplicates</code>
メソッドはロケーション情報（インデックス？）がない場合をドロップする。
<code>org.apache.hudi.client.HoodieWriteClient#combineOnCondition</code>
メソッドはキーに基づきreduce処理する。 という違いがあるようだ。</p>
<p>org/apache/hudi/client/HoodieWriteClient.java:300</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> JavaRDD&lt;WriteStatus&gt; <span class="title">bulkInsert</span><span class="params">(JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; records, <span class="keyword">final</span> String instantTime,</span></span></span><br><span class="line"><span class="function"><span class="params">    Option&lt;UserDefinedBulkInsertPartitioner&gt; bulkInsertPartitioner)</span> </span>&#123;</span><br><span class="line">  HoodieTable&lt;T&gt; table = getTableAndInitCtx(WriteOperationType.BULK_INSERT);</span><br><span class="line">  setOperationType(WriteOperationType.BULK_INSERT);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// De-dupe/merge if needed</span></span><br><span class="line">    JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; dedupedRecords =</span><br><span class="line">        combineOnCondition(config.shouldCombineBeforeInsert(), records, config.getInsertShuffleParallelism());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bulkInsertInternal(dedupedRecords, instantTime, table, bulkInsertPartitioner);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (e <span class="keyword">instanceof</span> HoodieInsertException) &#123;</span><br><span class="line">      <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HoodieInsertException(<span class="string">"Failed to bulk insert for commit time "</span> + instantTime, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上記の通り、
<code>org.apache.hudi.client.HoodieWriteClient#bulkInsertInternal</code>
メソッドが中で用いられている。
当該メソッドでは、再パーティションないしソートが行われた後、書き込みが実行される。</p>
<p>org/apache/hudi/client/HoodieWriteClient.java:412</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;WriteStatus&gt; writeStatusRDD = repartitionedRecords</span><br><span class="line">    .mapPartitionsWithIndex(<span class="keyword">new</span> BulkInsertMapFunction&lt;T&gt;(instantTime, config, table, fileIDPrefixes), <span class="keyword">true</span>)</span><br><span class="line">    .flatMap(List::iterator);</span><br></pre></td></tr></table></figure>
<p>ポイントは、<code>org.apache.hudi.execution.BulkInsertMapFunction</code>
クラスである。 このクラスが関数として渡されている。
<code>org.apache.hudi.execution.BulkInsertMapFunction#call</code>
メソッドは以下の通り。</p>
<p>org/apache/hudi/execution/BulkInsertMapFunction.java:52</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; call(Integer partition, Iterator&lt;HoodieRecord&lt;T&gt;&gt; sortedRecordItr) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> CopyOnWriteLazyInsertIterable&lt;&gt;(sortedRecordItr, config, instantTime, hoodieTable,</span><br><span class="line">      fileIDPrefixes.get(partition), hoodieTable.getSparkTaskContextSupplier());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>org.apache.hudi.execution.CopyOnWriteLazyInsertIterable</code>
クラスについては、別の節で書いたとおり。</p>
<h4><span id="insert">insert</span></h4>
<p><code>org.apache.hudi.client.HoodieWriteClient#insert</code>
メソッド。</p>
<p>大まかな構造は、 <code>bulkInsert</code> と同様。 ポイントは、
<code>org.apache.hudi.client.HoodieWriteClient#upsertRecordsInternal</code>
メソッド。</p>
<p>org/apache/hudi/client/HoodieWriteClient.java:229</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> JavaRDD&lt;WriteStatus&gt; <span class="title">insert</span><span class="params">(JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; records, <span class="keyword">final</span> String instantTime)</span> </span>&#123;</span><br><span class="line">  HoodieTable&lt;T&gt; table = getTableAndInitCtx(WriteOperationType.INSERT);</span><br><span class="line">  setOperationType(WriteOperationType.INSERT);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// De-dupe/merge if needed</span></span><br><span class="line">    JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; dedupedRecords =</span><br><span class="line">        combineOnCondition(config.shouldCombineBeforeInsert(), records, config.getInsertShuffleParallelism());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> upsertRecordsInternal(dedupedRecords, instantTime, table, <span class="keyword">false</span>);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (e <span class="keyword">instanceof</span> HoodieInsertException) &#123;</span><br><span class="line">      <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HoodieInsertException(<span class="string">"Failed to insert for commit time "</span> + instantTime, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上記の通り、挿入対象のデータを表すRDDを引数に取り、データを書き込む。
これは、upsertのときと同じメソッドである。第4引数でinsertかupsertかを分ける。</p>
<p>当該メソッドは以下の通り。 <code>bulkInsert</code>
と同様にリパーティションなどを経て、
<code>org.apache.hudi.table.HoodieTable#handleUpsertPartition</code>
が呼び出される。</p>
<p>org/apache/hudi/client/HoodieWriteClient.java:457</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">private</span> JavaRDD&lt;WriteStatus&gt; <span class="title">upsertRecordsInternal</span><span class="params">(JavaRDD&lt;HoodieRecord&lt;T&gt;&gt; preppedRecords, String instantTime,</span></span></span><br><span class="line"><span class="function"><span class="params">      HoodieTable&lt;T&gt; hoodieTable, <span class="keyword">final</span> <span class="keyword">boolean</span> isUpsert)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">(snip)</span><br><span class="line"></span><br><span class="line">    JavaRDD&lt;WriteStatus&gt; writeStatusRDD = partitionedRecords.mapPartitionsWithIndex((partition, recordItr) -&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (isUpsert) &#123;</span><br><span class="line">        <span class="keyword">return</span> hoodieTable.handleUpsertPartition(instantTime, partition, recordItr, partitioner);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> hoodieTable.handleInsertPartition(instantTime, partition, recordItr, partitioner);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>).flatMap(List::iterator);</span><br><span class="line"></span><br><span class="line">(snip)</span><br></pre></td></tr></table></figure>
<p><code>org.apache.hudi.table.HoodieTable#handleUpsertPartition</code>
と <code>org.apache.hudi.table.HoodieTable#handleInsertPartition</code>
が用いられている。 今回は、insertなので後者。</p>
<p>なお、
<code>org.apache.hudi.table.HoodieCopyOnWriteTable#handleInsertPartition</code>
は以下の通り、実態としては
<code>org.apache.hudi.table.HoodieCopyOnWriteTable#handleUpsertPartition</code>
である。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleInsertPartition(String instantTime, Integer partition, Iterator recordItr,</span><br><span class="line">                                                         Partitioner partitioner) &#123;</span><br><span class="line">  <span class="keyword">return</span> handleUpsertPartition(instantTime, partition, recordItr, partitioner);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当該メソッドは以下の通り。
insertやupsertでは、RDDひとつを1バケットと表現している。
バケットの情報から、insertやupdateの情報を取得して用いる。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleUpsertPartition(String instantTime, Integer partition, Iterator recordItr,</span><br><span class="line">                                                         Partitioner partitioner) &#123;</span><br><span class="line">  UpsertPartitioner upsertPartitioner = (UpsertPartitioner) partitioner;</span><br><span class="line">  BucketInfo binfo = upsertPartitioner.getBucketInfo(partition);</span><br><span class="line">  BucketType btype = binfo.bucketType;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (btype.equals(BucketType.INSERT)) &#123;</span><br><span class="line">      <span class="keyword">return</span> handleInsert(instantTime, binfo.fileIdPrefix, recordItr);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (btype.equals(BucketType.UPDATE)) &#123;</span><br><span class="line">      <span class="keyword">return</span> handleUpdate(instantTime, binfo.partitionPath, binfo.fileIdPrefix, recordItr);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> HoodieUpsertException(<span class="string">"Unknown bucketType "</span> + btype + <span class="string">" for partition :"</span> + partition);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    String msg = <span class="string">"Error upserting bucketType "</span> + btype + <span class="string">" for partition :"</span> + partition;</span><br><span class="line">    LOG.error(msg, t);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HoodieUpsertException(msg, t);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>例えば、insertの場合は、
<code>org.apache.hudi.table.HoodieCopyOnWriteTable#handleInsert</code>
が呼び出される。 当該メソッドでは、戻り値として
<code>org.apache.hudi.execution.CopyOnWriteLazyInsertIterable#CopyOnWriteLazyInsertIterable</code>
が返される。</p>
<p>org/apache/hudi/table/HoodieCopyOnWriteTable.java:186</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleInsert(String instantTime, String idPfx, Iterator&lt;HoodieRecord&lt;T&gt;&gt; recordItr)</span><br><span class="line">    <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="comment">// This is needed since sometimes some buckets are never picked in getPartition() and end up with 0 records</span></span><br><span class="line">  <span class="keyword">if</span> (!recordItr.hasNext()) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Empty partition"</span>);</span><br><span class="line">    <span class="keyword">return</span> Collections.singletonList((List&lt;WriteStatus&gt;) Collections.EMPTY_LIST).iterator();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> CopyOnWriteLazyInsertIterable&lt;&gt;(recordItr, config, instantTime, <span class="keyword">this</span>, idPfx, sparkTaskContextSupplier);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>このメソッドについては上記ですでに説明したとおり。</p>
<h4><span id="hoodiecopyonwritetableと-hoodiemergeonreadtable">HoodieCopyOnWriteTable
と HoodieMergeOnReadTable</span></h4>
<p>テーブルの種類によって、書き込みの実装上どういう違いがあるかを確認する。</p>
<p>例えば、<code>handleInsert</code>
メソッドを確認する。なお、当該メソッドには同期的、非同期的な処理方式がそれぞれ実装されている。</p>
<p>HoodieCopyOnWriteTableの場合は以下の通り。</p>
<p>org/apache/hudi/table/HoodieCopyOnWriteTable.java:186</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleInsert(String instantTime, String idPfx, Iterator&lt;HoodieRecord&lt;T&gt;&gt; recordItr)</span><br><span class="line">    <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="comment">// This is needed since sometimes some buckets are never picked in getPartition() and end up with 0 records</span></span><br><span class="line">  <span class="keyword">if</span> (!recordItr.hasNext()) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Empty partition"</span>);</span><br><span class="line">    <span class="keyword">return</span> Collections.singletonList((List&lt;WriteStatus&gt;) Collections.EMPTY_LIST).iterator();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> CopyOnWriteLazyInsertIterable&lt;&gt;(recordItr, config, instantTime, <span class="keyword">this</span>, idPfx, sparkTaskContextSupplier);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleInsert(String instantTime, String partitionPath, String fileId,</span><br><span class="line">    Iterator&lt;HoodieRecord&lt;T&gt;&gt; recordItr) &#123;</span><br><span class="line">  HoodieCreateHandle createHandle =</span><br><span class="line">      <span class="keyword">new</span> HoodieCreateHandle(config, instantTime, <span class="keyword">this</span>, partitionPath, fileId, recordItr, sparkTaskContextSupplier);</span><br><span class="line">  createHandle.write();</span><br><span class="line">  <span class="keyword">return</span> Collections.singletonList(Collections.singletonList(createHandle.close())).iterator();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上が非同期的な方式、下が同期的な方式と見られる。
なお、実装上は同期的な処理方式は今は使われていないようにもみえるが、要確認。</p>
<p>HoodieMergeOnReadTableの場合は、非同期的な処理だけoverrideされている。</p>
<p>org/apache/hudi/table/HoodieMergeOnReadTable.java:120</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Iterator&lt;List&lt;WriteStatus&gt;&gt; handleInsert(String instantTime, String idPfx, Iterator&lt;HoodieRecord&lt;T&gt;&gt; recordItr)</span><br><span class="line">    <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="comment">// If canIndexLogFiles, write inserts to log files else write inserts to parquet files</span></span><br><span class="line">  <span class="keyword">if</span> (index.canIndexLogFiles()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> MergeOnReadLazyInsertIterable&lt;&gt;(recordItr, config, instantTime, <span class="keyword">this</span>, idPfx, sparkTaskContextSupplier);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">super</span>.handleInsert(instantTime, idPfx, recordItr);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<!-- vim: set et tw=0 ts=2 sw=2: -->

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://dobachi.github.io/memo-blog/2020/03/25/Hudi/" data-id="clkrsgrog01dc1vp75b8aop93" class="article-share-link"><i class="fas fa-share"></i>共有</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/memo-blog/2020/04/10/Storage-Layer-Software-for-Machine-Learning/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">新しい記事</strong>
            <div class="article-nav-title">
                
                    機械学習向けのFeature StoreないしStorage Layer Software
                
            </div>
        </a>
    
    
        <a href="/memo-blog/2020/03/06/pandoc-template-and-css/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">古い記事</strong>
            <div class="article-nav-title">pandoc template and css</div>
        </a>
    
</nav>


    
</article>


    
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最近の記事</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/">Knowledge Management</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/Data-Spaces/">Data Spaces</a></p>
                            <p class="item-title"><a href="/memo-blog/2023/08/01/Open-project-of-EDC-Connector-with-Intellij/" class="title">Open project of EDC Connector with Intellij</a></p>
                            <p class="item-date"><time datetime="2023-08-01T01:46:35.000Z" itemprop="datePublished">2023-08-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/">Knowledge Management</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/Hexo/">Hexo</a></p>
                            <p class="item-title"><a href="/memo-blog/2022/05/02/GitHub-Actions-for-Hexo-with-Pandoc/" class="title">GitHub Actions for Hexo with Pandoc</a></p>
                            <p class="item-date"><time datetime="2022-05-02T00:57:25.000Z" itemprop="datePublished">2022-05-02</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/">Knowledge Management</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/Hyper-V/">Hyper-V</a></p>
                            <p class="item-title"><a href="/memo-blog/2022/02/03/Nest-VM-on-Hyper-V/" class="title">Nest VM on Hyper-V</a></p>
                            <p class="item-date"><time datetime="2022-02-03T14:47:34.000Z" itemprop="datePublished">2022-02-03</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/">Knowledge Management</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/Data-Catalog/">Data Catalog</a></p>
                            <p class="item-title"><a href="/memo-blog/2022/01/20/Getting-started-CKAN/" class="title">Getting_started_CKAN</a></p>
                            <p class="item-date"><time datetime="2022-01-20T09:04:05.000Z" itemprop="datePublished">2022-01-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/">Knowledge Management</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="/memo-blog/categories/Knowledge-Management/Stream-Processing/">Stream Processing</a></p>
                            <p class="item-title"><a href="/memo-blog/2022/01/18/Latency-Guarantee-of-Stream-Processing/" class="title">Latency Guarantee of Stream Processing</a></p>
                            <p class="item-date"><time datetime="2022-01-17T15:49:18.000Z" itemprop="datePublished">2022-01-18</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">カテゴリ</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/">Clipping</a><span class="category-list-count">16</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/AI/">AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Camera/">Camera</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Camera/Lighting/">Lighting</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Cloud/">Cloud</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Database/">Database</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Kafka/">Kafka</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/List/">List</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/List/Research/">Research</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Management/">Management</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/PostgreSQL/">PostgreSQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Stream-Processing/">Stream Processing</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Uber/">Uber</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Vim/">Vim</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Clipping/Windows-Tools/">Windows Tools</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/">Home server</a><span class="category-list-count">14</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/File-server/">File server</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Hardware/">Hardware</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Nature-Remo/">Nature Remo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Network/">Network</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Remote-desktop/">Remote desktop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Ubuntu/">Ubuntu</a><span class="category-list-count">8</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Ubuntu/Adobe-Reader/">Adobe Reader</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Ubuntu/Gnome/">Gnome</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Ubuntu/KVM/">KVM</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Ubuntu/OneDrive/">OneDrive</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Ubuntu/vim/">vim</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Home-server/Video-processing/">Video processing</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/">Knowledge Management</a><span class="category-list-count">153</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Alluxio/">Alluxio</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/BaaS/">BaaS</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Configuration-Management/">Configuration Management</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Configuration-Management/Ansible/">Ansible</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Catalog/">Data Catalog</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Catalog/CKAN/">CKAN</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Collaboration/">Data Collaboration</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Collaboration/Delta-Sharing/">Delta Sharing</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Collaboration/X-Road/">X-Road</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Engineering/">Data Engineering</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Engineering/Data-Lineage/">Data Lineage</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Engineering/Data-Transformation/">Data Transformation</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Mesh/">Data Mesh</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Processing-Engine/">Data Processing Engine</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Spaces/">Data Spaces</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Data-Spaces/EDC/">EDC</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Documentation/">Documentation</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Flask/">Flask</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/GPD-Pocket/">GPD Pocket</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/GPD-Pocket/Device/">Device</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/GPD-Pocket/Device/Bluetooth/">Bluetooth</a><span class="category-list-count">1</span></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/HBase/">HBase</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hadoop/">Hadoop</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hadoop/Ambari/">Ambari</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hadoop/BigTop/">BigTop</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hadoop/HDP/">HDP</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hexo/">Hexo</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Home-Network/">Home Network</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hyper/">Hyper</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hyper/Plugin/">Plugin</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Hyper-V/">Hyper-V</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Keyboard/">Keyboard</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Keyboard/Corne-Chocolate/">Corne Chocolate</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Keyboard/QMK/">QMK</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Kubernetes/">Kubernetes</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/">Machine Learning</a><span class="category-list-count">25</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Analytics-Zoo/">Analytics Zoo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/AutoML/">AutoML</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Data-Platform/">Data Platform</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Flow-Engine/">Flow Engine</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Kaggle/">Kaggle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/MLflow/">MLflow</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Model/">Model</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Model/Cross-Validation/">Cross Validation</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Model/Data-Leakage/">Data Leakage</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Model/Partial-Dependency-Plot/">Partial Dependency Plot</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Model/XGBoost/">XGBoost</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Model-Management/">Model Management</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Model-Management/Clipper/">Clipper</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/OpML/">OpML</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Preparation/">Preparation</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Software-Engineering-Patterns/">Software Engineering Patterns</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Stream-Processing/">Stream Processing</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Visualization/">Visualization</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Visualization/Seaborn/">Seaborn</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Machine-Learning/Word2Vec/">Word2Vec</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Messaging-System/">Messaging System</a><span class="category-list-count">15</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Messaging-System/Kafka/">Kafka</a><span class="category-list-count">14</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Metadata-Management/">Metadata Management</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Monitering/">Monitering</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Open-Data/">Open Data</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Open-Data/Scraping/">Scraping</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Open-Data/Tellus/">Tellus</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Pinot/">Pinot</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Power-Grid-Data/">Power Grid Data</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Python/">Python</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Python/Jupyter/">Jupyter</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Python/Pipenv/">Pipenv</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Python/pyenv/">pyenv</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/SQLAlchemy/">SQLAlchemy</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Scala/">Scala</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Scala/SBT/">SBT</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Spark/">Spark</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Spark/Spark-Summit/">Spark Summit</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Storage-Layer/">Storage Layer</a><span class="category-list-count">13</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Storage-Layer/Delta-Lake/">Delta Lake</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Storage-Layer/Hudi/">Hudi</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Storage-Layer/Minio/">Minio</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Stream-Processing/">Stream Processing</a><span class="category-list-count">9</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Stream-Processing/Apache-Edgent/">Apache Edgent</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Stream-Processing/Kappa-Architecture/">Kappa Architecture</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Stream-Processing/MillWheel/">MillWheel</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Stream-Processing/Twitter-Heron/">Twitter Heron</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Tools/">Tools</a><span class="category-list-count">8</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Tools/Git/">Git</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Tools/Intellij/">Intellij</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Tools/Selenium/">Selenium</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Tools/tmux/">tmux</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/WSL/">WSL</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/WSL/CentOS/">CentOS</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/WSL/Docker/">Docker</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/WSL/Terminal-tool/">Terminal tool</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/WSL/Vagrant/">Vagrant</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/WSL/X-Window/">X Window</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Windows/">Windows</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Windows/Ansible/">Ansible</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Windows/Docker/">Docker</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Windows/Hyper-V/">Hyper-V</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/Zeppelin/">Zeppelin</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/ZooKeeper/">ZooKeeper</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Knowledge-Management/vim/">vim</a><span class="category-list-count">5</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/">Research</a><span class="category-list-count">14</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/AWS/">AWS</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Conference/">Conference</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Conference/DevSumi/">DevSumi</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Data-Analytics/">Data Analytics</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Data-Analytics/Tools/">Tools</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Machine-Learning/">Machine Learning</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Machine-Learning/BigDL/">BigDL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Machine-Learning/TensorFlow/">TensorFlow</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/NVM/">NVM</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/SX-Aurora-Frovedis/">SX-Aurora/Frovedis</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Trends/">Trends</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Video-processing/">Video processing</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Video-processing/BlazeIt/">BlazeIt</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Visualization/">Visualization</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/memo-blog/categories/Research/Visualization/Superset/">Superset</a><span class="category-list-count">1</span></li></ul></li></ul></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">アーカイブ</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2023/08/">8月 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2022/05/">5月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2022/02/">2月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2022/01/">1月 2022</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/10/">10月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/09/">9月 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/08/">8月 2021</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/07/">7月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/06/">6月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/05/">5月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/04/">4月 2021</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/02/">2月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2021/01/">1月 2021</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/12/">12月 2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/11/">11月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/10/">10月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/09/">9月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/08/">8月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/07/">7月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/06/">6月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/05/">5月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/04/">4月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/03/">3月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/02/">2月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2020/01/">1月 2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/12/">12月 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/11/">11月 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/10/">10月 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/09/">9月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/08/">8月 2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/07/">7月 2019</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/06/">6月 2019</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/05/">5月 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/04/">4月 2019</a><span class="archive-list-count">15</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/03/">3月 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/02/">2月 2019</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2019/01/">1月 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2018/12/">12月 2018</a><span class="archive-list-count">17</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2018/11/">11月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2018/10/">10月 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/memo-blog/archives/2018/09/">9月 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">タグ</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/AI/">AI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/AWS/">AWS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Academia/">Academia</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Adobe-Reader/">Adobe Reader</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Alluxio/">Alluxio</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Ambari/">Ambari</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Analytics-Zoo/">Analytics Zoo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Ansible/">Ansible</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Apache-Edgent/">Apache Edgent</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Apache-Hudi/">Apache Hudi</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Apache-Kafka/">Apache Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Apache-Spark/">Apache Spark</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Apple/">Apple</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/AutoML/">AutoML</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Automagica/">Automagica</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Autonomous-Database/">Autonomous Database</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/BaaS/">BaaS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Behavioral-Economics/">Behavioral Economics</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Big-Data/">Big Data</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/BigDL/">BigDL</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/BigTop/">BigTop</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/BlazeIt/">BlazeIt</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Blog/">Blog</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Bluetooth/">Bluetooth</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/CDC/">CDC</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Camera/">Camera</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/CentOS/">CentOS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/CentOS7/">CentOS7</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/CircleCI/">CircleCI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Clipper/">Clipper</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Clipping/">Clipping</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Cloud/">Cloud</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Comcast/">Comcast</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Computing-resource/">Computing resource</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Conference/">Conference</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Configuration-Management/">Configuration Management</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Corne-Chocolate/">Corne Chocolate</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Cross-Validation/">Cross Validation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/DB/">DB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Dask/">Dask</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Analysis/">Data Analysis</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Analytics/">Data Analytics</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Lake/">Data Lake</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Leakage/">Data Leakage</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Lineage/">Data Lineage</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Mesh/">Data Mesh</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Platform/">Data Platform</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Processing-Engine/">Data Processing Engine</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Spaces/">Data Spaces</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Data-Transformation/">Data Transformation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Delta-Lake/">Delta Lake</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Delta-Sharing/">Delta Sharing</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/DevSumi/">DevSumi</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Docker/">Docker</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Dockerfile/">Dockerfile</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Druid/">Druid</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/EDC/">EDC</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Flask/">Flask</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Flow-Engine/">Flow Engine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Frovedis/">Frovedis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/GIS/">GIS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/GNOME/">GNOME</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/GPD-Pocket/">GPD Pocket</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Git/">Git</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/GitHub-Actions/">GitHub Actions</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Google/">Google</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Goverment/">Goverment</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Graceful-Shutdown/">Graceful Shutdown</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Gradle/">Gradle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/HBase/">HBase</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/HDP/">HDP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/HPC/">HPC</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Hadoop/">Hadoop</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Hexo/">Hexo</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Hexo-Plugin/">Hexo Plugin</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Hyper/">Hyper</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Hyper-V/">Hyper-V</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/IEEE/">IEEE</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/IPv6/">IPv6</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Icarus/">Icarus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Incident/">Incident</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Intel/">Intel</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Intellij/">Intellij</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/JSON/">JSON</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Java/">Java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Jupyter/">Jupyter</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/KVM/">KVM</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kafak-Connect/">Kafak Connect</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kafka/">Kafka</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kafka-Connect/">Kafka Connect</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kafka-Streams/">Kafka Streams</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kafka-Summit/">Kafka Summit</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kaggle/">Kaggle</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kappa-Architecture/">Kappa Architecture</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Keyboard/">Keyboard</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kinesis/">Kinesis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Kubernetes/">Kubernetes</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Lambda-Architecture/">Lambda Architecture</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Lighthing/">Lighthing</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/LinkedIn/">LinkedIn</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/MATE-Desktop/">MATE Desktop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/ML-Model-Management/">ML Model Management</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/ML-Ops/">ML Ops</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/MLflow/">MLflow</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">29</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Machine-Learning-Lifecycle/">Machine Learning Lifecycle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Machine-Learning-Lifecycle/">Machine Learning Lifecycle/</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Management/">Management</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Map/">Map</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Markdown/">Markdown</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Messaging-System/">Messaging System</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Metadata-Management/">Metadata Management</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/MillWheel/">MillWheel</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Minikube/">Minikube</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Minio/">Minio</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Model/">Model</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Model-Management/">Model Management</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Monitering/">Monitering</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Mouse/">Mouse</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/NERDTree/">NERDTree</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/NVM/">NVM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Nature-Remo/">Nature Remo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Network/">Network</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/OLAP/">OLAP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/OneDrive/">OneDrive</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/OpML/">OpML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Open-Data/">Open Data</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Open-Messaging-Benchmark/">Open Messaging Benchmark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/OpenML/">OpenML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Oracle/">Oracle</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/PAPIDS/">PAPIDS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/PDF/">PDF</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Pandoc/">Pandoc</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Paper/">Paper</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Parquet/">Parquet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Partial-Dependency-Plot/">Partial Dependency Plot</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Pinot/">Pinot</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Pipenv/">Pipenv</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/PostgreSQL/">PostgreSQL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Power-Grid-Data/">Power Grid Data</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/PowerShell/">PowerShell</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Preparation/">Preparation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Profiler/">Profiler</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Pulsar/">Pulsar</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/PySpark/">PySpark</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Python/">Python</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Python3/">Python3</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/QMK/">QMK</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Query-Engine/">Query Engine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/RDBMS/">RDBMS</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/RPA/">RPA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Redshift/">Redshift</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Research-later/">Research later</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/S3/">S3</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/SBT/">SBT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/SQLAlchemy/">SQLAlchemy</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/SQLite/">SQLite</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/SX-Aurora/">SX-Aurora</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Samba/">Samba</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Scala/">Scala</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Scraping/">Scraping</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Seaborn/">Seaborn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Security/">Security</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Session/">Session</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Slenium/">Slenium</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Smart-Home/">Smart Home</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Snowflake/">Snowflake</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Software-Engineering-Patterns/">Software Engineering Patterns</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Spark/">Spark</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Spark-Summit/">Spark Summit</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Sphinx/">Sphinx</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Statistic/">Statistic</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Stonebraker/">Stonebraker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Storage/">Storage</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Storage-Engine/">Storage Engine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Storage-Layer/">Storage Layer</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Storage-Layer-Software/">Storage Layer Software</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Stream-Processing/">Stream Processing</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Superset/">Superset</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Supervision/">Supervision</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Tellus/">Tellus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/TensorFlow/">TensorFlow</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/TensorFlowOnSpark/">TensorFlowOnSpark</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Tools/">Tools</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Trends/">Trends</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Troubleshoot/">Troubleshoot</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Twitter/">Twitter</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Twitter-Heron/">Twitter Heron</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Uber/">Uber</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Ubuntu/">Ubuntu</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/VMWare/">VMWare</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Vagrant/">Vagrant</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Vault/">Vault</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Vector-Engine/">Vector Engine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Video-Processing/">Video Processing</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Vim/">Vim</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Visualization/">Visualization</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/WSL/">WSL</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Web/">Web</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/WhereHows/">WhereHows</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/WiFi/">WiFi</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/WiFi6/">WiFi6</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Windows/">Windows</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Windows-Tools/">Windows Tools</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Word/">Word</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Word2Vec/">Word2Vec</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/X-Window/">X Window</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/X-Road/">X-Road</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/XGBoost/">XGBoost</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/Zeppelin/">Zeppelin</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/ZooKeeper/">ZooKeeper</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/bug/">bug</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/dein/">dein</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/dstat/">dstat</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/fsync/">fsync</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/git/">git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/keyboard/">keyboard</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/libvirt/">libvirt</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/markdown/">markdown</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/nltk/">nltk</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/pandoc/">pandoc</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/pyenv/">pyenv</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/tmux/">tmux</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/vim/">vim</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/memo-blog/tags/windows/">windows</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">タグクラウド</h3>
        <div class="widget tagcloud">
            <a href="/memo-blog/tags/AI/" style="font-size: 10px;">AI</a> <a href="/memo-blog/tags/AWS/" style="font-size: 10px;">AWS</a> <a href="/memo-blog/tags/Academia/" style="font-size: 10px;">Academia</a> <a href="/memo-blog/tags/Adobe-Reader/" style="font-size: 10px;">Adobe Reader</a> <a href="/memo-blog/tags/Alluxio/" style="font-size: 10.83px;">Alluxio</a> <a href="/memo-blog/tags/Ambari/" style="font-size: 10px;">Ambari</a> <a href="/memo-blog/tags/Analytics-Zoo/" style="font-size: 10px;">Analytics Zoo</a> <a href="/memo-blog/tags/Ansible/" style="font-size: 11.67px;">Ansible</a> <a href="/memo-blog/tags/Apache-Edgent/" style="font-size: 10px;">Apache Edgent</a> <a href="/memo-blog/tags/Apache-Hudi/" style="font-size: 10px;">Apache Hudi</a> <a href="/memo-blog/tags/Apache-Kafka/" style="font-size: 10px;">Apache Kafka</a> <a href="/memo-blog/tags/Apache-Spark/" style="font-size: 11.67px;">Apache Spark</a> <a href="/memo-blog/tags/Apple/" style="font-size: 10px;">Apple</a> <a href="/memo-blog/tags/AutoML/" style="font-size: 10.83px;">AutoML</a> <a href="/memo-blog/tags/Automagica/" style="font-size: 10px;">Automagica</a> <a href="/memo-blog/tags/Autonomous-Database/" style="font-size: 10px;">Autonomous Database</a> <a href="/memo-blog/tags/BaaS/" style="font-size: 10px;">BaaS</a> <a href="/memo-blog/tags/Behavioral-Economics/" style="font-size: 10px;">Behavioral Economics</a> <a href="/memo-blog/tags/Big-Data/" style="font-size: 10px;">Big Data</a> <a href="/memo-blog/tags/BigDL/" style="font-size: 10.83px;">BigDL</a> <a href="/memo-blog/tags/BigTop/" style="font-size: 10.83px;">BigTop</a> <a href="/memo-blog/tags/BlazeIt/" style="font-size: 10px;">BlazeIt</a> <a href="/memo-blog/tags/Blog/" style="font-size: 10px;">Blog</a> <a href="/memo-blog/tags/Bluetooth/" style="font-size: 10px;">Bluetooth</a> <a href="/memo-blog/tags/CDC/" style="font-size: 10px;">CDC</a> <a href="/memo-blog/tags/Camera/" style="font-size: 10px;">Camera</a> <a href="/memo-blog/tags/CentOS/" style="font-size: 10px;">CentOS</a> <a href="/memo-blog/tags/CentOS7/" style="font-size: 11.67px;">CentOS7</a> <a href="/memo-blog/tags/CircleCI/" style="font-size: 10px;">CircleCI</a> <a href="/memo-blog/tags/Clipper/" style="font-size: 10px;">Clipper</a> <a href="/memo-blog/tags/Clipping/" style="font-size: 10px;">Clipping</a> <a href="/memo-blog/tags/Cloud/" style="font-size: 10px;">Cloud</a> <a href="/memo-blog/tags/Comcast/" style="font-size: 10px;">Comcast</a> <a href="/memo-blog/tags/Computing-resource/" style="font-size: 10px;">Computing resource</a> <a href="/memo-blog/tags/Conference/" style="font-size: 10px;">Conference</a> <a href="/memo-blog/tags/Configuration-Management/" style="font-size: 10px;">Configuration Management</a> <a href="/memo-blog/tags/Corne-Chocolate/" style="font-size: 10px;">Corne Chocolate</a> <a href="/memo-blog/tags/Cross-Validation/" style="font-size: 10px;">Cross Validation</a> <a href="/memo-blog/tags/DB/" style="font-size: 10px;">DB</a> <a href="/memo-blog/tags/Dask/" style="font-size: 10.83px;">Dask</a> <a href="/memo-blog/tags/Data-Analysis/" style="font-size: 10.83px;">Data Analysis</a> <a href="/memo-blog/tags/Data-Analytics/" style="font-size: 10px;">Data Analytics</a> <a href="/memo-blog/tags/Data-Lake/" style="font-size: 10px;">Data Lake</a> <a href="/memo-blog/tags/Data-Leakage/" style="font-size: 10px;">Data Leakage</a> <a href="/memo-blog/tags/Data-Lineage/" style="font-size: 10px;">Data Lineage</a> <a href="/memo-blog/tags/Data-Mesh/" style="font-size: 10px;">Data Mesh</a> <a href="/memo-blog/tags/Data-Platform/" style="font-size: 10px;">Data Platform</a> <a href="/memo-blog/tags/Data-Processing-Engine/" style="font-size: 10.83px;">Data Processing Engine</a> <a href="/memo-blog/tags/Data-Spaces/" style="font-size: 10px;">Data Spaces</a> <a href="/memo-blog/tags/Data-Transformation/" style="font-size: 10.83px;">Data Transformation</a> <a href="/memo-blog/tags/Delta-Lake/" style="font-size: 17.5px;">Delta Lake</a> <a href="/memo-blog/tags/Delta-Sharing/" style="font-size: 12.5px;">Delta Sharing</a> <a href="/memo-blog/tags/DevSumi/" style="font-size: 10px;">DevSumi</a> <a href="/memo-blog/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/memo-blog/tags/Dockerfile/" style="font-size: 10.83px;">Dockerfile</a> <a href="/memo-blog/tags/Druid/" style="font-size: 10px;">Druid</a> <a href="/memo-blog/tags/EDC/" style="font-size: 10px;">EDC</a> <a href="/memo-blog/tags/Flask/" style="font-size: 11.67px;">Flask</a> <a href="/memo-blog/tags/Flow-Engine/" style="font-size: 10px;">Flow Engine</a> <a href="/memo-blog/tags/Frovedis/" style="font-size: 10px;">Frovedis</a> <a href="/memo-blog/tags/GIS/" style="font-size: 10px;">GIS</a> <a href="/memo-blog/tags/GNOME/" style="font-size: 10px;">GNOME</a> <a href="/memo-blog/tags/GPD-Pocket/" style="font-size: 10px;">GPD Pocket</a> <a href="/memo-blog/tags/Git/" style="font-size: 10.83px;">Git</a> <a href="/memo-blog/tags/GitHub-Actions/" style="font-size: 10px;">GitHub Actions</a> <a href="/memo-blog/tags/Google/" style="font-size: 10px;">Google</a> <a href="/memo-blog/tags/Goverment/" style="font-size: 10px;">Goverment</a> <a href="/memo-blog/tags/Graceful-Shutdown/" style="font-size: 10px;">Graceful Shutdown</a> <a href="/memo-blog/tags/Gradle/" style="font-size: 10px;">Gradle</a> <a href="/memo-blog/tags/HBase/" style="font-size: 10px;">HBase</a> <a href="/memo-blog/tags/HDP/" style="font-size: 10px;">HDP</a> <a href="/memo-blog/tags/HPC/" style="font-size: 10px;">HPC</a> <a href="/memo-blog/tags/Hadoop/" style="font-size: 11.67px;">Hadoop</a> <a href="/memo-blog/tags/Hexo/" style="font-size: 16.67px;">Hexo</a> <a href="/memo-blog/tags/Hexo-Plugin/" style="font-size: 10px;">Hexo Plugin</a> <a href="/memo-blog/tags/Hyper/" style="font-size: 10.83px;">Hyper</a> <a href="/memo-blog/tags/Hyper-V/" style="font-size: 10.83px;">Hyper-V</a> <a href="/memo-blog/tags/IEEE/" style="font-size: 10.83px;">IEEE</a> <a href="/memo-blog/tags/IPv6/" style="font-size: 10px;">IPv6</a> <a href="/memo-blog/tags/Icarus/" style="font-size: 10px;">Icarus</a> <a href="/memo-blog/tags/Incident/" style="font-size: 10px;">Incident</a> <a href="/memo-blog/tags/Intel/" style="font-size: 10px;">Intel</a> <a href="/memo-blog/tags/Intellij/" style="font-size: 10.83px;">Intellij</a> <a href="/memo-blog/tags/JSON/" style="font-size: 10px;">JSON</a> <a href="/memo-blog/tags/Java/" style="font-size: 10px;">Java</a> <a href="/memo-blog/tags/Jupyter/" style="font-size: 10.83px;">Jupyter</a> <a href="/memo-blog/tags/KVM/" style="font-size: 11.67px;">KVM</a> <a href="/memo-blog/tags/Kafak-Connect/" style="font-size: 10px;">Kafak Connect</a> <a href="/memo-blog/tags/Kafka/" style="font-size: 19.17px;">Kafka</a> <a href="/memo-blog/tags/Kafka-Connect/" style="font-size: 10px;">Kafka Connect</a> <a href="/memo-blog/tags/Kafka-Streams/" style="font-size: 10.83px;">Kafka Streams</a> <a href="/memo-blog/tags/Kafka-Summit/" style="font-size: 10px;">Kafka Summit</a> <a href="/memo-blog/tags/Kaggle/" style="font-size: 15px;">Kaggle</a> <a href="/memo-blog/tags/Kappa-Architecture/" style="font-size: 10px;">Kappa Architecture</a> <a href="/memo-blog/tags/Keyboard/" style="font-size: 10.83px;">Keyboard</a> <a href="/memo-blog/tags/Kinesis/" style="font-size: 10px;">Kinesis</a> <a href="/memo-blog/tags/Kubernetes/" style="font-size: 11.67px;">Kubernetes</a> <a href="/memo-blog/tags/Lambda-Architecture/" style="font-size: 10px;">Lambda Architecture</a> <a href="/memo-blog/tags/Lighthing/" style="font-size: 10px;">Lighthing</a> <a href="/memo-blog/tags/LinkedIn/" style="font-size: 12.5px;">LinkedIn</a> <a href="/memo-blog/tags/MATE-Desktop/" style="font-size: 10px;">MATE Desktop</a> <a href="/memo-blog/tags/ML-Model-Management/" style="font-size: 10.83px;">ML Model Management</a> <a href="/memo-blog/tags/ML-Ops/" style="font-size: 10px;">ML Ops</a> <a href="/memo-blog/tags/MLflow/" style="font-size: 10px;">MLflow</a> <a href="/memo-blog/tags/Machine-Learning/" style="font-size: 20px;">Machine Learning</a> <a href="/memo-blog/tags/Machine-Learning-Lifecycle/" style="font-size: 10px;">Machine Learning Lifecycle</a> <a href="/memo-blog/tags/Machine-Learning-Lifecycle/" style="font-size: 10px;">Machine Learning Lifecycle/</a> <a href="/memo-blog/tags/Management/" style="font-size: 10px;">Management</a> <a href="/memo-blog/tags/Map/" style="font-size: 10px;">Map</a> <a href="/memo-blog/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/memo-blog/tags/Messaging-System/" style="font-size: 10px;">Messaging System</a> <a href="/memo-blog/tags/Metadata-Management/" style="font-size: 10px;">Metadata Management</a> <a href="/memo-blog/tags/MillWheel/" style="font-size: 10px;">MillWheel</a> <a href="/memo-blog/tags/Minikube/" style="font-size: 10px;">Minikube</a> <a href="/memo-blog/tags/Minio/" style="font-size: 10.83px;">Minio</a> <a href="/memo-blog/tags/Model/" style="font-size: 12.5px;">Model</a> <a href="/memo-blog/tags/Model-Management/" style="font-size: 12.5px;">Model Management</a> <a href="/memo-blog/tags/Monitering/" style="font-size: 10px;">Monitering</a> <a href="/memo-blog/tags/Mouse/" style="font-size: 10px;">Mouse</a> <a href="/memo-blog/tags/NERDTree/" style="font-size: 10px;">NERDTree</a> <a href="/memo-blog/tags/NVM/" style="font-size: 10px;">NVM</a> <a href="/memo-blog/tags/Nature-Remo/" style="font-size: 10px;">Nature Remo</a> <a href="/memo-blog/tags/Network/" style="font-size: 10px;">Network</a> <a href="/memo-blog/tags/OLAP/" style="font-size: 10px;">OLAP</a> <a href="/memo-blog/tags/OneDrive/" style="font-size: 10px;">OneDrive</a> <a href="/memo-blog/tags/OpML/" style="font-size: 10px;">OpML</a> <a href="/memo-blog/tags/Open-Data/" style="font-size: 10.83px;">Open Data</a> <a href="/memo-blog/tags/Open-Messaging-Benchmark/" style="font-size: 10px;">Open Messaging Benchmark</a> <a href="/memo-blog/tags/OpenML/" style="font-size: 10px;">OpenML</a> <a href="/memo-blog/tags/Oracle/" style="font-size: 10px;">Oracle</a> <a href="/memo-blog/tags/PAPIDS/" style="font-size: 10px;">PAPIDS</a> <a href="/memo-blog/tags/PDF/" style="font-size: 10px;">PDF</a> <a href="/memo-blog/tags/Pandoc/" style="font-size: 10px;">Pandoc</a> <a href="/memo-blog/tags/Paper/" style="font-size: 18.33px;">Paper</a> <a href="/memo-blog/tags/Parquet/" style="font-size: 10px;">Parquet</a> <a href="/memo-blog/tags/Partial-Dependency-Plot/" style="font-size: 10px;">Partial Dependency Plot</a> <a href="/memo-blog/tags/Pinot/" style="font-size: 10px;">Pinot</a> <a href="/memo-blog/tags/Pipenv/" style="font-size: 10px;">Pipenv</a> <a href="/memo-blog/tags/PostgreSQL/" style="font-size: 10px;">PostgreSQL</a> <a href="/memo-blog/tags/Power-Grid-Data/" style="font-size: 10px;">Power Grid Data</a> <a href="/memo-blog/tags/PowerShell/" style="font-size: 10px;">PowerShell</a> <a href="/memo-blog/tags/Preparation/" style="font-size: 10.83px;">Preparation</a> <a href="/memo-blog/tags/Profiler/" style="font-size: 10px;">Profiler</a> <a href="/memo-blog/tags/Pulsar/" style="font-size: 10px;">Pulsar</a> <a href="/memo-blog/tags/PySpark/" style="font-size: 12.5px;">PySpark</a> <a href="/memo-blog/tags/Python/" style="font-size: 17.5px;">Python</a> <a href="/memo-blog/tags/Python3/" style="font-size: 10px;">Python3</a> <a href="/memo-blog/tags/QMK/" style="font-size: 10px;">QMK</a> <a href="/memo-blog/tags/Query-Engine/" style="font-size: 10px;">Query Engine</a> <a href="/memo-blog/tags/RDBMS/" style="font-size: 10.83px;">RDBMS</a> <a href="/memo-blog/tags/RPA/" style="font-size: 10px;">RPA</a> <a href="/memo-blog/tags/Redshift/" style="font-size: 10px;">Redshift</a> <a href="/memo-blog/tags/Research-later/" style="font-size: 10px;">Research later</a> <a href="/memo-blog/tags/S3/" style="font-size: 10px;">S3</a> <a href="/memo-blog/tags/SBT/" style="font-size: 10px;">SBT</a> <a href="/memo-blog/tags/SQLAlchemy/" style="font-size: 10.83px;">SQLAlchemy</a> <a href="/memo-blog/tags/SQLite/" style="font-size: 10px;">SQLite</a> <a href="/memo-blog/tags/SX-Aurora/" style="font-size: 10px;">SX-Aurora</a> <a href="/memo-blog/tags/Samba/" style="font-size: 10px;">Samba</a> <a href="/memo-blog/tags/Scala/" style="font-size: 10px;">Scala</a> <a href="/memo-blog/tags/Scraping/" style="font-size: 10px;">Scraping</a> <a href="/memo-blog/tags/Seaborn/" style="font-size: 10px;">Seaborn</a> <a href="/memo-blog/tags/Security/" style="font-size: 10px;">Security</a> <a href="/memo-blog/tags/Session/" style="font-size: 10px;">Session</a> <a href="/memo-blog/tags/Slenium/" style="font-size: 10px;">Slenium</a> <a href="/memo-blog/tags/Smart-Home/" style="font-size: 10px;">Smart Home</a> <a href="/memo-blog/tags/Snowflake/" style="font-size: 10px;">Snowflake</a> <a href="/memo-blog/tags/Software-Engineering-Patterns/" style="font-size: 10px;">Software Engineering Patterns</a> <a href="/memo-blog/tags/Spark/" style="font-size: 15.83px;">Spark</a> <a href="/memo-blog/tags/Spark-Summit/" style="font-size: 10px;">Spark Summit</a> <a href="/memo-blog/tags/Sphinx/" style="font-size: 10px;">Sphinx</a> <a href="/memo-blog/tags/Statistic/" style="font-size: 10px;">Statistic</a> <a href="/memo-blog/tags/Stonebraker/" style="font-size: 10px;">Stonebraker</a> <a href="/memo-blog/tags/Storage/" style="font-size: 10px;">Storage</a> <a href="/memo-blog/tags/Storage-Engine/" style="font-size: 10px;">Storage Engine</a> <a href="/memo-blog/tags/Storage-Layer/" style="font-size: 11.67px;">Storage Layer</a> <a href="/memo-blog/tags/Storage-Layer-Software/" style="font-size: 10px;">Storage Layer Software</a> <a href="/memo-blog/tags/Stream-Processing/" style="font-size: 18.33px;">Stream Processing</a> <a href="/memo-blog/tags/Superset/" style="font-size: 10px;">Superset</a> <a href="/memo-blog/tags/Supervision/" style="font-size: 10px;">Supervision</a> <a href="/memo-blog/tags/Tellus/" style="font-size: 10px;">Tellus</a> <a href="/memo-blog/tags/TensorFlow/" style="font-size: 11.67px;">TensorFlow</a> <a href="/memo-blog/tags/TensorFlowOnSpark/" style="font-size: 10.83px;">TensorFlowOnSpark</a> <a href="/memo-blog/tags/Tools/" style="font-size: 10px;">Tools</a> <a href="/memo-blog/tags/Trends/" style="font-size: 10px;">Trends</a> <a href="/memo-blog/tags/Troubleshoot/" style="font-size: 10px;">Troubleshoot</a> <a href="/memo-blog/tags/Twitter/" style="font-size: 10px;">Twitter</a> <a href="/memo-blog/tags/Twitter-Heron/" style="font-size: 10px;">Twitter Heron</a> <a href="/memo-blog/tags/Uber/" style="font-size: 10.83px;">Uber</a> <a href="/memo-blog/tags/Ubuntu/" style="font-size: 15px;">Ubuntu</a> <a href="/memo-blog/tags/VMWare/" style="font-size: 10px;">VMWare</a> <a href="/memo-blog/tags/Vagrant/" style="font-size: 10.83px;">Vagrant</a> <a href="/memo-blog/tags/Vault/" style="font-size: 10px;">Vault</a> <a href="/memo-blog/tags/Vector-Engine/" style="font-size: 10px;">Vector Engine</a> <a href="/memo-blog/tags/Video-Processing/" style="font-size: 10px;">Video Processing</a> <a href="/memo-blog/tags/Vim/" style="font-size: 10.83px;">Vim</a> <a href="/memo-blog/tags/Visualization/" style="font-size: 10.83px;">Visualization</a> <a href="/memo-blog/tags/WSL/" style="font-size: 14.17px;">WSL</a> <a href="/memo-blog/tags/Web/" style="font-size: 10px;">Web</a> <a href="/memo-blog/tags/WhereHows/" style="font-size: 10px;">WhereHows</a> <a href="/memo-blog/tags/WiFi/" style="font-size: 10px;">WiFi</a> <a href="/memo-blog/tags/WiFi6/" style="font-size: 10px;">WiFi6</a> <a href="/memo-blog/tags/Windows/" style="font-size: 13.33px;">Windows</a> <a href="/memo-blog/tags/Windows-Tools/" style="font-size: 10px;">Windows Tools</a> <a href="/memo-blog/tags/Word/" style="font-size: 10px;">Word</a> <a href="/memo-blog/tags/Word2Vec/" style="font-size: 10px;">Word2Vec</a> <a href="/memo-blog/tags/X-Window/" style="font-size: 10px;">X Window</a> <a href="/memo-blog/tags/X-Road/" style="font-size: 10px;">X-Road</a> <a href="/memo-blog/tags/XGBoost/" style="font-size: 10px;">XGBoost</a> <a href="/memo-blog/tags/Zeppelin/" style="font-size: 10px;">Zeppelin</a> <a href="/memo-blog/tags/ZooKeeper/" style="font-size: 12.5px;">ZooKeeper</a> <a href="/memo-blog/tags/bug/" style="font-size: 10px;">bug</a> <a href="/memo-blog/tags/dein/" style="font-size: 10px;">dein</a> <a href="/memo-blog/tags/dstat/" style="font-size: 10px;">dstat</a> <a href="/memo-blog/tags/fsync/" style="font-size: 10px;">fsync</a> <a href="/memo-blog/tags/git/" style="font-size: 10px;">git</a> <a href="/memo-blog/tags/keyboard/" style="font-size: 10px;">keyboard</a> <a href="/memo-blog/tags/libvirt/" style="font-size: 10px;">libvirt</a> <a href="/memo-blog/tags/markdown/" style="font-size: 10px;">markdown</a> <a href="/memo-blog/tags/nltk/" style="font-size: 10px;">nltk</a> <a href="/memo-blog/tags/pandoc/" style="font-size: 11.67px;">pandoc</a> <a href="/memo-blog/tags/pyenv/" style="font-size: 10px;">pyenv</a> <a href="/memo-blog/tags/tmux/" style="font-size: 10.83px;">tmux</a> <a href="/memo-blog/tags/vim/" style="font-size: 14.17px;">vim</a> <a href="/memo-blog/tags/windows/" style="font-size: 10px;">windows</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">リンク</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fas fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2023 dobachi<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        


    
        <script src="/memo-blog/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/memo-blog/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/memo-blog/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/memo-blog/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>